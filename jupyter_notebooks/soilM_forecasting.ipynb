{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Input, Dense, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Flatten, GRU, LSTM\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import tensorflow as tf\n",
    "from pymlx import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windowed(dataset, seq_length, horizon, feat_cols, resp_cols, region_col, split=0.2, resp_width=0,\n",
    "                        predict_current=False):\n",
    "    \"\"\"\n",
    "    This function takes data and creates a windowed dataframe to be used in time-series analysis. \n",
    "    dataset: [panda df] the raw dataframe that a time series windowed df will be created from\n",
    "    seq_length: [int] the sequence length, the amount of time to be used to perform the \n",
    "                time-series analysis\n",
    "    horizon: [int] how far into the future you wish to predict\n",
    "    feat_cols: [list] a list of column names that make up the feature space\n",
    "    resp_cols: [list] a list of column names that make up the response\n",
    "    region_col: [str] the name of the column that different time-series will be created on, i.e. \n",
    "                different regions that contain\n",
    "                independent time-series.\n",
    "    split: [float] A percent split for the test set, i.e. 0.2 equals a 80/20 split for the \n",
    "                train/test sets.\n",
    "    resp_width: [int] If you want to predict out to a set distance you set the horizon to that \n",
    "                    time point and this value to 0, however if you want to predict every value \n",
    "                    between let's say now and some point in the future you set horizon to 1 and\n",
    "                    the resp_width to that point. The algorithm will then predict every time point.\n",
    "    predict_current: [bool] horizon needs to be set to 1 for this to work. This will predict at \n",
    "                    the current time so if there is a sequence length of 2 instead of forecasting \n",
    "                    out the horizon length, the model\n",
    "                    will predict at the current time.\n",
    "    \"\"\"\n",
    "\n",
    "    if ((predict_current) and (horizon is not 1)):\n",
    "        raise ValueError('If predict_current is set to True, then Horizon must be set to 1.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if (any(dataset[feat_cols + resp_cols].isnull().sum()) != 0):\n",
    "        raise ValueError('There is missing data in at least one of the columns supplied in keep_cols. \\\n",
    "                         Please impute this missing data as needed.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # check to see if there are same features in both the response and the features list\n",
    "    resp_and_feats = [var for var in feat_cols if var in resp_cols]\n",
    "\n",
    "    regions = list(dataset[region_col].unique())\n",
    "    big_dict = {}\n",
    "\n",
    "    for i in range(len(regions)):\n",
    "        big_dict.update({regions[i]: dataset[dataset[region_col] == regions[i]]})\n",
    "    features = len(feat_cols)\n",
    "    response = len(resp_cols)\n",
    "    if resp_width == 0:\n",
    "        train_X_all, test_X_all = np.empty((0, seq_length, features)), np.empty((0, seq_length, features))\n",
    "        train_y_all, test_y_all = np.empty((0, response)), np.empty((0, response))\n",
    "    else:\n",
    "        train_X_all, test_X_all = np.empty((0, sequence_length, features)), np.empty((0, sequence_length, features))\n",
    "        train_y_all, test_y_all = np.empty((0, resp_width, response)), np.empty((0, resp_width, response))\n",
    "\n",
    "    for region in regions:\n",
    "        big_dict[region] = big_dict[region][resp_cols + feat_cols]\n",
    "        if resp_and_feats:\n",
    "            big_dict[region] = big_dict[region].loc[:, ~big_dict[region].columns.duplicated()]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        length = len(big_dict[region])\n",
    "        test_length = int(length * split)  # 20% test set\n",
    "\n",
    "        df_x = big_dict[region][feat_cols]\n",
    "        df_y = big_dict[region][resp_cols]\n",
    "        ts_x = df_x.values\n",
    "        ts_y = df_y.values\n",
    "\n",
    "        train_length = length - test_length\n",
    "\n",
    "        train_X, train_y, test_X, test_y = [], [], [], []\n",
    "\n",
    "        if (predict_current):\n",
    "            z = 2\n",
    "            q = 1\n",
    "        else:\n",
    "            z = 1\n",
    "            q = 0\n",
    "\n",
    "        if (resp_width != 0):\n",
    "            for i in range(train_length - sequence_length - horizon - resp_width):\n",
    "                train_X.append(ts_x[i:i + sequence_length])\n",
    "                train_y.append(ts_y[i + sequence_length + horizon - z:i + sequence_length + horizon - z + resp_width])\n",
    "            for i in range(-test_length, -resp_width):\n",
    "                test_X.append(ts_x[i - sequence_length - horizon + 1:i - horizon + 1])\n",
    "                test_y.append(ts_y[i - q:i - q + (resp_width)])\n",
    "\n",
    "        else:\n",
    "            for i in range(train_length - seq_length - horizon):\n",
    "                train_X.append(ts_x[i:i + seq_length])\n",
    "                train_y.append(ts_y[i + seq_length + horizon - z])\n",
    "            for i in range(-test_length, 0):\n",
    "                test_X.append(ts_x[i - seq_length - horizon + 1:i - horizon + 1])\n",
    "                test_y.append(ts_y[i - q])\n",
    "\n",
    "        train_X, train_y = np.array(train_X), np.array(train_y)\n",
    "        test_X, test_y = np.array(test_X), np.array(test_y)\n",
    "\n",
    "        train_X_all = np.append(train_X_all, train_X, axis=0)\n",
    "        test_X_all = np.append(test_X_all, test_X, axis=0)\n",
    "        train_y_all = np.append(train_y_all, train_y, axis=0)\n",
    "        test_y_all = np.append(test_y_all, test_y, axis=0)\n",
    "\n",
    "    # normalize\n",
    "    mean_x = train_X_all.mean(0)\n",
    "    std_x = train_X_all.std(0)\n",
    "\n",
    "    train_X = (train_X_all - mean_x) / std_x\n",
    "    test_X = (test_X_all - mean_x) / std_x\n",
    "    train_X = train_X.astype('float32')\n",
    "    test_X = test_X.astype('float32')\n",
    "\n",
    "    mean_y = train_y_all.mean(0)\n",
    "    std_y = train_y_all.std(0)\n",
    "\n",
    "    train_y = (train_y_all - mean_y) / std_y\n",
    "    test_y = (test_y_all - mean_y) / std_y\n",
    "    train_y = train_y.astype('float32')\n",
    "    test_y = test_y.astype('float32')\n",
    "\n",
    "    if resp_width != 0:\n",
    "        std_y = std_y.ravel()\n",
    "        mean_y = mean_y.ravel()\n",
    "        train_y = train_y.reshape(train_y.shape[0], train_y.shape[1] * response)\n",
    "        test_y = test_y.reshape(test_y.shape[0], test_y.shape[1] * response)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print('train_X shape:', np.shape(train_X))\n",
    "    print('train_y shape:', np.shape(train_y))\n",
    "    print('test_X shape:', np.shape(test_X))\n",
    "    print('test_y shape:', np.shape(test_y))\n",
    "\n",
    "    return train_X, test_X, train_y, test_y, mean_x, std_x, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def compute_mape_minMax(model, x, y):\n",
    "    forecasts = model.predict(x, batch_size=len(x))\n",
    "    forecasts = (forecasts *  (max_soilT - min_soilT)) + min_soilT\n",
    "    y_denom = (y * (max_soilT - min_soilT)) + min_soilT\n",
    "    return np.mean(np.abs((y_denom - forecasts) / y_denom))\n",
    "\n",
    "\n",
    "def compute_mape_centerScale(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "    forecasts = forecasts.reshape(forecasts.shape[0],dense)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    sub_result = np.abs((y_denom - forecasts) / y_denom )\n",
    "    # remove rows that are divided by 0 or a very small number\n",
    "    idxinf = np.where(sub_result == np.inf)\n",
    "    idx = np.where(sub_result > 1)\n",
    "    total_remove = len(idxinf[0]) + len(idx[0])\n",
    "    #print('Removed %f percent of the data, a total of %d rows.'% (((total_remove/len(forecasts))*100), total_remove))\n",
    "    sub_result = np.delete(sub_result, idxinf[0],0)\n",
    "    sub_result = np.delete(sub_result, idx[0], 0)\n",
    "    result = (np.mean(sub_result))\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_mae(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "#     forecasts = forecasts.reshape(forecasts.shape[0],dense)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    result = mean_absolute_error(y_pred=forecasts, y_true=y_denom)\n",
    "    return result\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    # print('Train Mean Absolute Percentage Error (MAPE): {0:.3f}'.format(compute_mape_centerScale(model, train_X, train_y)))\n",
    "    # print('Test Mean Absolute Percentage Error (MAPE): {0:.3f}'.format(compute_mape_centerScale(model, test_X, test_y)))\n",
    "    return(compute_mape_centerScale(model, train_X, train_y), compute_mape_centerScale(model, test_X, test_y))\n",
    "\n",
    "def test_mae(model):\n",
    "    yhat_train = model.predict(train_X)\n",
    "    yhat_test = model.predict(test_X)\n",
    "    return(compute_mae(model, train_X, train_y), compute_mae(model, test_X, test_y))\n",
    "\n",
    "\n",
    "def report(train, test):\n",
    "    train_mean = np.asarray(train).mean()\n",
    "    train_std = np.asarray(train).std()\n",
    "    test_mean = np.asarray(test).mean()\n",
    "    test_std = np.asarray(test).std()\n",
    "    train = str('Training MAE %f ± %f'% (train_mean, train_std))\n",
    "    test = str('Testing MAE %f ± %f'% (test_mean, test_std))\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>field</th>\n",
       "      <th>soilM_avg</th>\n",
       "      <th>precip.cm</th>\n",
       "      <th>tair.C</th>\n",
       "      <th>rh.pct</th>\n",
       "      <th>wind_sp.m_per_s</th>\n",
       "      <th>irradiance.w_per_m.2</th>\n",
       "      <th>average_sand</th>\n",
       "      <th>average_silt</th>\n",
       "      <th>average_clay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-29</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.212173</td>\n",
       "      <td>0.045</td>\n",
       "      <td>7.654167</td>\n",
       "      <td>68.083333</td>\n",
       "      <td>3.179167</td>\n",
       "      <td>121.708333</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-30</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.210993</td>\n",
       "      <td>0.369</td>\n",
       "      <td>9.354167</td>\n",
       "      <td>78.250000</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>0.023</td>\n",
       "      <td>6.945833</td>\n",
       "      <td>68.625000</td>\n",
       "      <td>5.112500</td>\n",
       "      <td>122.666667</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.209532</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.225000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>3.220833</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-11-02</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.207929</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.862500</td>\n",
       "      <td>44.958333</td>\n",
       "      <td>6.091667</td>\n",
       "      <td>124.041667</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date field  soilM_avg  precip.cm    tair.C     rh.pct  \\\n",
       "0  2011-10-29   AES   0.212173      0.045  7.654167  68.083333   \n",
       "1  2011-10-30   AES   0.210993      0.369  9.354167  78.250000   \n",
       "2  2011-10-31   AES   0.209983      0.023  6.945833  68.625000   \n",
       "3  2011-11-01   AES   0.209532      0.000  2.225000  66.250000   \n",
       "4  2011-11-02   AES   0.207929      0.000  4.862500  44.958333   \n",
       "\n",
       "   wind_sp.m_per_s  irradiance.w_per_m.2  average_sand  average_silt  \\\n",
       "0         3.179167            121.708333     14.891866     60.796955   \n",
       "1         3.562500             72.500000     14.891866     60.796955   \n",
       "2         5.112500            122.666667     14.891866     60.796955   \n",
       "3         3.220833            127.500000     14.891866     60.796955   \n",
       "4         6.091667            124.041667     14.891866     60.796955   \n",
       "\n",
       "   average_clay  \n",
       "0     24.311179  \n",
       "1     24.311179  \n",
       "2     24.311179  \n",
       "3     24.311179  \n",
       "4     24.311179  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "FILE_PATH = os.path.join(CWD, \"../data/time_series_soilM_averaged.csv\")\n",
    "dataset = pd.read_csv(FILE_PATH)\n",
    "dataset.head()\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "dataset = dataset.set_index(['date'])\n",
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'field', 'soilM_avg'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                      0\n",
       "field                     0\n",
       "soilM_avg               248\n",
       "precip.cm                 0\n",
       "tair.C                    0\n",
       "rh.pct                    0\n",
       "wind_sp.m_per_s           0\n",
       "irradiance.w_per_m.2      0\n",
       "average_sand              0\n",
       "average_silt              0\n",
       "average_clay              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_cols = ['soilM_avg']\n",
    "feat_cols = ['precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s', 'irradiance.w_per_m.2', 'average_clay',\n",
    "       'average_sand', 'average_silt']\n",
    "keep_cols = resp_cols + feat_cols\n",
    "\n",
    "sequence_length = 10\n",
    "horizon = 3\n",
    "resp_width = 0\n",
    "dense = len(resp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Windowed DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is missing data in at least one of the columns supplied in keep_cols.                          Please impute this missing data as needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b7634e2d709b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                                      \u001b[0mregion_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'field'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                                      \u001b[0mresp_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                                      predict_current=False)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5b30f15e3f84>\u001b[0m in \u001b[0;36mmake_windowed\u001b[0;34m(dataset, seq_length, horizon, feat_cols, resp_cols, region_col, split, resp_width, predict_current)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresp_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There is missing data in at least one of the columns supplied in keep_cols.                          Please impute this missing data as needed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: There is missing data in at least one of the columns supplied in keep_cols.                          Please impute this missing data as needed."
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y, mean_x, std_x, mean_y, std_y = make_windowed(dataset=dataset, \n",
    "                                                                                     seq_length=sequence_length,\n",
    "                                                                                     horizon=horizon,\n",
    "                                                                                     resp_cols=resp_cols,\n",
    "                                                                                     feat_cols=feat_cols,\n",
    "                                                                                     region_col='field',\n",
    "                                                                                     resp_width=resp_width,\n",
    "                                                                                     predict_current=False)\n",
    "dim = train_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script performs an evaluation of the physical model, comparing the SMR model to actual soil moisture readings in-ground. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import gdal\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import coordinates for field sites\n",
    "coords = pd.read_csv('D:/Dane/UW MSDS/2018-1-Winter Quarter/DATA 591 Data Science Capstone II/HydroSatML/data/sensor_coords/SCF_TierII_site_coords.csv')\n",
    "coords_AES = coords[0:12]\n",
    "coords_OD = coords[24:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sensor data\n",
    "sensors = pd.read_csv('D:/Dane/UW MSDS/2018-1-Winter Quarter/DATA 591 Data Science Capstone II/HydroSatML/data/data_for_models/final_join.csv',\n",
    "                      usecols=['field', 'sensor', 'date', 'depth_1', 'depth_2', 'depth_3', 'depth_4', 'depth_5'])\n",
    "\n",
    "# remove duplicate rows\n",
    "sensors.drop_duplicates(inplace=True)\n",
    "\n",
    "# add column with converted ordinal date\n",
    "sensors['DOY'] = sensors['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').strftime('%j'))\n",
    "\n",
    "# add column with year\n",
    "sensors['year'] = sensors['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').strftime('%Y'))\n",
    "\n",
    "# add column with average of all 5 depths\n",
    "sensors['avg'] = sensors[['depth_1', 'depth_2', 'depth_3', 'depth_4', 'depth_5']].mean(numeric_only=True, axis=1)\n",
    "\n",
    "# add corresponding SMR filename column for lookup\n",
    "sensors['filename'] = 'mc_' + sensors['DOY'] + sensors['year'] + '.asc'\n",
    "\n",
    "# drop all rows with NaN for 'avg' column\n",
    "sensors.dropna(subset=['avg'], inplace=True)\n",
    "\n",
    "# return sensor data for only fields 'AES' and 'OD'\n",
    "sensors = sensors[(sensors['field'] == 'AES') | (sensors['field'] == 'OD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create list to loop through when opening raster files\n",
    "raster_files = sensors[['field', 'filename']].drop_duplicates()\n",
    "\n",
    "# loop through raster files, opening and obtaining soil moisture values from SMR\n",
    "SMR_predictions = []\n",
    "missing_files = []\n",
    "\n",
    "for i in range(len(raster_files)):\n",
    "    \n",
    "    # get field name, filename, and directory\n",
    "    field = raster_files.iloc[i][0]\n",
    "    filename = raster_files.iloc[i][1]\n",
    "    directory = 'D:/Dane/UW MSDS/2018-1-Winter Quarter/DATA 591 Data Science Capstone II/Local/' + field + '/rz.' + filename\n",
    "    \n",
    "    # use appropriate field coordinates\n",
    "    if field == 'AES':\n",
    "        points = coords_AES\n",
    "    elif field == 'OD':\n",
    "        points = coords_OD\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # check to see if the corresponding SMR file exists\n",
    "    if os.path.isfile(directory) == False:\n",
    "        missing_files.append(filename)\n",
    "#         SMR_predictions.extend([[field, 0, filename, 'NA']]*12)\n",
    "    else:\n",
    "    \n",
    "        # open raster file\n",
    "        raster = gdal.Open(directory)\n",
    "\n",
    "        # georeference info\n",
    "        transform = raster.GetGeoTransform()\n",
    "        xOrigin = transform[0]\n",
    "        yOrigin = transform[3]\n",
    "        pixelWidth = transform[1]\n",
    "        pixelHeight = transform[5]\n",
    "\n",
    "        band = raster.GetRasterBand(1)\n",
    "\n",
    "        data = band.ReadAsArray()\n",
    "\n",
    "        # loop through coordinates\n",
    "        sensor_num = 0\n",
    "        for point in points[['east', 'north']].values.tolist():\n",
    "\n",
    "            sensor_num += 1\n",
    "            \n",
    "            x = point[0]\n",
    "            y = point[1]\n",
    "\n",
    "            xOffset = int((x - xOrigin) / pixelWidth)\n",
    "            yOffset = int((y - yOrigin) / pixelHeight)\n",
    "\n",
    "            value = data[yOffset][xOffset]\n",
    "\n",
    "            SMR_predictions.append([field, sensor_num, filename, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(SMR_predictions, columns=['field', 'sensor', 'filename', 'SMR_prediction'])\n",
    "result = pd.merge(sensors, predictions, on=['field', 'sensor', 'filename'])\n",
    "result['error'] = result['avg'] - result['SMR_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(result['error']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result['error']**2).mean()**(1/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

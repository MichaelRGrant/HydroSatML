{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from pymlx import *\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Input, Dense, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Flatten, GRU, LSTM\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "#     forecasts = forecasts.reshape(forecasts.shape[0],dense)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    result = mean_absolute_error(y_pred=forecasts, y_true=y_denom)\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_mape_centerScale(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "#     forecasts = forecasts.reshape(forecasts.shape[0],1)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    sub_result = np.abs((y_denom - forecasts) / y_denom )\n",
    "    result = (np.mean(sub_result))\n",
    "    return result\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def test_mae(model):\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test = model.predict(X_test)\n",
    "    return(compute_mae(model, X_train, y_train), compute_mae(model, X_test, y_test))\n",
    "\n",
    "\n",
    "def report(train, test):\n",
    "    train_mean = np.asarray(train).mean()\n",
    "    train_std = np.asarray(train).std()\n",
    "    test_mean = np.asarray(test).mean()\n",
    "    test_std = np.asarray(test).std()\n",
    "    train = str('Training MAE %f ± %f'% (train_mean, train_std))\n",
    "    test = str('Testing MAE %f ± %f'% (test_mean, test_std))\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndre_data = pd.read_csv('../HydroSatML/data/final_join_subbed_missing_soilM.csv')\n",
    "# ndre_data_sub_30 = pd.read_csv('../HydroSatML/data/final_join_subbed_bare_soil.csv')\n",
    "# ndre_data_sub_40 = pd.read_csv('../HydroSatML/data/final_join_subbed_bare_soil_40.csv')\n",
    "# ndre_data_lag_40 = pd.read_csv('../data/final_join_subbed_bare_soil_with_lag_40_2.csv')\n",
    "ndre_data_lag_40_EXACT = pd.read_csv('../data/final_join_subbed_bare_soil_with_lag_40_EXACT_NDRE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['field', 'average_adjacent', 'stdev_adjacent', 'sensor', 'date',\n",
       "       'sensor_full_name', 'depth_1', 'depth_2', 'depth_3', 'year',\n",
       "       'precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s',\n",
       "       'irradiance.w_per_m.2', 'sand_1', 'sand_2', 'sand_3', 'silt_1',\n",
       "       'silt_2', 'silt_3', 'clay_1', 'clay_2', 'clay_3', 'l3_depth_1',\n",
       "       'l3_depth_2', 'l3_depth_3', 'l5_depth_1', 'l5_depth_2', 'l5_depth_3',\n",
       "       'l7_depth_1', 'l7_depth_2', 'l7_depth_3', 'avg_soilM', 'avg_soilM_l3',\n",
       "       'avg_soilM_l5', 'avg_soilM_l7', 'avg_clay', 'avg_sand', 'avg_silt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndre_data_lag_40.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_cols = ['avg_soilM', 'average_adjacent', 'precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s', \n",
    "#              'irradiance.w_per_m.2', 'sand_1', 'sand_2', 'sand_3', 'silt_1', 'silt_2', 'silt_3', 'clay_1', \n",
    "#              'clay_2', 'clay_3']\n",
    "keep_cols = ['avg_soilM', 'ndre_val', 'precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s', \n",
    "             'irradiance.w_per_m.2', 'avg_clay', 'avg_sand', 'avg_silt']\n",
    "\n",
    "dataset = ndre_data_lag_40_EXACT[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,1:]\n",
    "X = X.values\n",
    "\n",
    "y = dataset.iloc[:,0]\n",
    "y = y.values\n",
    "\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "#### normalize\n",
    "\n",
    "mean_X = X_train.mean(axis=0)\n",
    "std_X = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean_X) / std_X\n",
    "X_test = (X_test - mean_X) / std_X\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "mean_y = y_train.mean(axis=0)\n",
    "std_y = y_train.std(axis=0)\n",
    "\n",
    "y_train = (y_train - mean_y) / std_y\n",
    "y_test = (y_test - mean_y) / std_y\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(84)\n",
    "tf.set_random_seed(84)\n",
    "\n",
    "def create_NN_model(units1=16,\n",
    "                    units2=16,\n",
    "                    units3=16,\n",
    "                    units4=16,\n",
    "                    layers=1,\n",
    "                    epochs=50,\n",
    "                    optimizer='adam',\n",
    "                    activation=ELU(),\n",
    "                    beta_1=0.9,\n",
    "                    beta_2=0.99,\n",
    "                    epsilon=1e-8,\n",
    "                    decay=0,\n",
    "                    schedule_decay=0.004,\n",
    "                    rho=0.8,\n",
    "                    lr=0.001,\n",
    "                    momentum=0.9,\n",
    "                    nesterov=False):\n",
    "    \n",
    "    if layers == 1:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units1, input_dim=dim, activation=activation))\n",
    "        model.add(Dense(1, activation=activation))\n",
    "    elif layers == 2:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units1, input_dim=dim, activation=activation))\n",
    "        model.add(Dense(units2, activation=activation))\n",
    "        model.add(Dense(1, activation=activation))\n",
    "    elif layers == 3:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units1, input_dim=dim, activation=activation))\n",
    "        model.add(Dense(units2, activation=activation))\n",
    "        model.add(Dense(units3, activation=activation))\n",
    "        model.add(Dense(1, activation=activation))\n",
    "    elif layers == 4:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units1, input_dim=dim, activation=activation))\n",
    "        model.add(Dense(units2, activation=activation))\n",
    "        model.add(Dense(units3, activation=activation))\n",
    "        model.add(Dense(units4, activation=activation))\n",
    "        model.add(Dense(1, activation=activation))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if(optimizer == 'SGD'):\n",
    "        sgd = SGD(lr=lr, momentum=momentum, decay=decay, nesterov=nesterov)\n",
    "    elif(optimizer == 'RMSprop'):\n",
    "        sgd = RMSprop(lr=lr, rho=rho)\n",
    "    elif(optimizer == 'Nadam'):\n",
    "        sgd = Nadam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, schedule_decay=schedule_decay)\n",
    "    elif(optimizer == 'Adagrad'):\n",
    "        sgd = Adagrad(lr=lr, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adadelta'):\n",
    "        sgd = Adadelta(lr=lr, rho=rho, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adam'):\n",
    "        sgd = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adamax'):\n",
    "        sgd = Adamax(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_NN_model, shuffle=True, verbose=0)\n",
    "\n",
    "units1 = [4,8,26,32,64]\n",
    "units2 = [4,8,16,32,64]\n",
    "units3 = [4,8,16,32,64]\n",
    "units4 = [4,8,16,32,64]\n",
    "\n",
    "layers = [1,2,3,4]\n",
    "epochs = [100]\n",
    "batch_size = [1,2,3,4]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation = ['relu', ELU()]\n",
    "decay = np.arange(0,.1,0.001).tolist()\n",
    "beta_1 = np.random.uniform(low=0.90, high=1.0, size=20).tolist()\n",
    "beta_2 = np.random.uniform(0.90, 1.0, 20).tolist()\n",
    "rho = np.random.uniform(0.80, 0.95, 20).tolist()\n",
    "epsilon = [1e-09, 1e-08,1e-07, 1e-06, 1e-05, 1e-04]\n",
    "schedule_decay = np.arange(0.001,0.01,0.0005).tolist()\n",
    "lr = [10**k for k in range(-5, -1)]\n",
    "\n",
    "param_grid = dict(units1=units1,\n",
    "                 units2=units2,\n",
    "                 units3=units3,\n",
    "                 units4=units4,\n",
    "                 layers=layers,\n",
    "                 epochs=epochs,\n",
    "                 optimizer=optimizer,\n",
    "                 activation=activation,\n",
    "                 lr=lr,\n",
    "                 schedule_decay=schedule_decay,\n",
    "                 epsilon=epsilon,\n",
    "                 rho=rho,\n",
    "                 beta_1=beta_1,\n",
    "                 beta_2=beta_2,\n",
    "                 decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n",
      "[CV] units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045558, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "[CV] units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039613, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.8s remaining:    0.0s\n",
      "[CV] units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=4, units1=64, schedule_decay=0.003, rho=0.8311758068665892, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.036000000000000004, beta_2=0.9835223929985658, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.037607, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.1s remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.042529, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   11.6s remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.046214, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.2s remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=4, units1=64, schedule_decay=0.007500000000000001, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=1, epsilon=1e-08, epochs=100, decay=0.042, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.031400, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.7s remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.060968, total=   2.5s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   19.3s remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040861, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   21.9s remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=32, units1=4, schedule_decay=0.007, rho=0.9077619006529815, optimizer=Adagrad, lr=1e-05, layers=1, epsilon=1e-05, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9340763715814911, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.054090, total=   2.6s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   24.4s remaining:    0.0s\n",
      "[CV] units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu, score=0.046899, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.2s remaining:    0.0s\n",
      "[CV] units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu, score=0.042328, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   30.0s remaining:    0.0s\n",
      "[CV] units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=4, units1=8, schedule_decay=0.008, rho=0.8265195577225888, optimizer=RMSprop, lr=0.001, layers=2, epsilon=0.0001, epochs=100, decay=0.016, beta_2=0.9819408717834255, beta_1=0.9878814443880595, activation=relu, score=0.036734, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   32.8s remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu, score=0.046249, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   36.3s remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu, score=0.039372, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   40.2s remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adam, lr=0.001, layers=3, epsilon=1e-06, epochs=100, decay=0.06, beta_2=0.936669600294371, beta_1=0.9423346068550754, activation=relu, score=0.036970, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   43.7s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu, score=0.046627, total=   3.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   46.7s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu, score=0.043034, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   49.8s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=16, units1=32, schedule_decay=0.0085, rho=0.9237553382634431, optimizer=RMSprop, lr=1e-05, layers=2, epsilon=0.0001, epochs=100, decay=0.008, beta_2=0.9875983196541405, beta_1=0.9340763715814911, activation=relu, score=0.041023, total=   3.1s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   52.9s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu, score=0.046212, total=   3.4s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   56.4s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu, score=0.039231, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   59.8s remaining:    0.0s\n",
      "[CV] units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=8, units1=32, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adamax, lr=0.001, layers=3, epsilon=1e-07, epochs=100, decay=0.054, beta_2=0.9914277888675106, beta_1=0.9895335561388198, activation=relu, score=0.039460, total=   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.046769, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.037598, total=   3.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=8, units1=32, schedule_decay=0.0025, rho=0.9164706059234075, optimizer=RMSprop, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.01, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.037062, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu \n",
      "[CV]  units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu, score=0.048596, total=   3.6s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu \n",
      "[CV]  units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu, score=0.040645, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=8, units3=32, units2=32, units1=4, schedule_decay=0.005, rho=0.8171340077735547, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-08, epochs=100, decay=0.012, beta_2=0.9819408717834255, beta_1=0.9870151785241231, activation=relu, score=0.038948, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu, score=0.046218, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu, score=0.039982, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=16, units1=26, schedule_decay=0.009500000000000001, rho=0.9021771605381883, optimizer=Nadam, lr=0.0001, layers=2, epsilon=1e-06, epochs=100, decay=0.057, beta_2=0.9355739559428804, beta_1=0.9564524845117608, activation=relu, score=0.039383, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.048293, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.046395, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=16, units2=8, units1=8, schedule_decay=0.0085, rho=0.8311758068665892, optimizer=Adadelta, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.069, beta_2=0.9914277888675106, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040128, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.042550, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.037889, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=32, units1=26, schedule_decay=0.007500000000000001, rho=0.9021771605381883, optimizer=Adagrad, lr=0.001, layers=4, epsilon=1e-07, epochs=100, decay=0.003, beta_2=0.9355739559428804, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.030303, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.048186, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.037787, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=8, units1=26, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=Adam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.036087, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.048038, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.039531, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=4, units1=8, schedule_decay=0.0055000000000000005, rho=0.9164706059234075, optimizer=Adagrad, lr=1e-05, layers=3, epsilon=1e-09, epochs=100, decay=0.022, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.040650, total=   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.049219, total=   4.5s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.038496, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=8, units1=4, schedule_decay=0.008, rho=0.8274457922887202, optimizer=Adamax, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.022, beta_2=0.9506816237267246, beta_1=0.9221854733741169, activation=relu, score=0.040520, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.7min remaining:    0.0s\n",
      "[CV] units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu, score=0.046647, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu, score=0.039531, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=16, units1=4, schedule_decay=0.0025, rho=0.8576629684993036, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-08, epochs=100, decay=0.031, beta_2=0.9729719183165639, beta_1=0.9221854733741169, activation=relu, score=0.040520, total=   5.6s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.041033, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039228, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.1min remaining:    0.0s\n",
      "[CV] units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.006, beta_2=0.9446772765480753, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.029142, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu, score=0.046647, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  3.3min remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu, score=0.039531, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  3.3min remaining:    0.0s\n",
      "[CV] units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=16, units2=8, units1=4, schedule_decay=0.0025, rho=0.8543654890157573, optimizer=RMSprop, lr=0.01, layers=2, epsilon=1e-07, epochs=100, decay=0.058, beta_2=0.9265849596843658, beta_1=0.9288119327973722, activation=relu, score=0.038608, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu, score=0.046304, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  3.5min remaining:    0.0s\n",
      "[CV] units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu, score=0.039201, total=   4.4s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=32, units2=4, units1=32, schedule_decay=0.0065, rho=0.9471585230297452, optimizer=SGD, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.011, beta_2=0.9875983196541405, beta_1=0.9423346068550754, activation=relu, score=0.038840, total=   4.6s\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045585, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.036016, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=4, units2=64, units1=26, schedule_decay=0.0085, rho=0.8753061375171187, optimizer=Adamax, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.073, beta_2=0.9101586361436318, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.029964, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.9min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.053380, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.050799, total=   5.2s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=4, units1=4, schedule_decay=0.003, rho=0.8501565753108836, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.035, beta_2=0.9101586361436318, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.042647, total=   5.2s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.046801, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.039666, total=   4.7s\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  4.3min remaining:    0.0s\n",
      "[CV] units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=8, units1=4, schedule_decay=0.007500000000000001, rho=0.8666082263911343, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.063, beta_2=0.926171906571784, beta_1=0.9423346068550754, activation=relu, score=0.040520, total=   4.8s\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  4.4min remaining:    0.0s\n",
      "[CV] units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu, score=0.068098, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu, score=0.047451, total=   5.2s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=32, units3=4, units2=64, units1=8, schedule_decay=0.0065, rho=0.9284217213227293, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.051000000000000004, beta_2=0.9506816237267246, beta_1=0.9423346068550754, activation=relu, score=0.043726, total=   6.2s\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu, score=0.048043, total=   5.3s\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  4.7min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu, score=0.038953, total=   5.2s\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=16, units1=8, schedule_decay=0.0055000000000000005, rho=0.9021771605381883, optimizer=SGD, lr=1e-05, layers=3, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9643806747145691, beta_1=0.9306830100304931, activation=relu, score=0.041957, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu, score=0.046457, total=   6.0s\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu, score=0.038939, total=   6.0s\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:  5.1min remaining:    0.0s\n",
      "[CV] units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8543654890157573, optimizer=Adam, lr=0.0001, layers=3, epsilon=0.0001, epochs=100, decay=0.07200000000000001, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=relu, score=0.039702, total=   6.1s\n",
      "[CV] units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.060802, total=   6.0s\n",
      "[CV] units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.046453, total=   6.3s\n",
      "[CV] units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=32, units2=32, units1=32, schedule_decay=0.005, rho=0.9471585230297452, optimizer=Adam, lr=1e-05, layers=3, epsilon=1e-08, epochs=100, decay=0.033, beta_2=0.9835223929985658, beta_1=0.9878814443880595, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039520, total=   7.0s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu, score=0.046647, total=   6.3s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu, score=0.039097, total=   6.6s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.001, rho=0.9164706059234075, optimizer=Adam, lr=0.0001, layers=2, epsilon=1e-09, epochs=100, decay=0.058, beta_2=0.9044671014559788, beta_1=0.9306830100304931, activation=relu, score=0.040252, total=   6.5s\n",
      "[CV] units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu, score=0.046753, total=   5.8s\n",
      "[CV] units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu, score=0.047549, total=   6.3s\n",
      "[CV] units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=16, units2=16, units1=64, schedule_decay=0.009000000000000001, rho=0.9471585230297452, optimizer=Adagrad, lr=0.0001, layers=1, epsilon=1e-08, epochs=100, decay=0.08700000000000001, beta_2=0.9875983196541405, beta_1=0.9792174674454335, activation=relu, score=0.039581, total=   6.1s\n",
      "[CV] units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu, score=0.045889, total=   6.3s\n",
      "[CV] units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu, score=0.039531, total=   6.5s\n",
      "[CV] units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=8, units3=4, units2=64, units1=8, schedule_decay=0.002, rho=0.9430742129490844, optimizer=SGD, lr=0.01, layers=3, epsilon=1e-08, epochs=100, decay=0.084, beta_2=0.9195057588183283, beta_1=0.9423346068550754, activation=relu, score=0.040520, total=   6.2s\n",
      "[CV] units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu, score=0.046744, total=   7.8s\n",
      "[CV] units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu, score=0.038090, total=   6.6s\n",
      "[CV] units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=64, units1=4, schedule_decay=0.0035, rho=0.8666082263911343, optimizer=Nadam, lr=0.001, layers=2, epsilon=1e-09, epochs=100, decay=0.075, beta_2=0.9506816237267246, beta_1=0.9895335561388198, activation=relu, score=0.036312, total=   6.6s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.052621, total=   6.0s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.048711, total=   6.0s\n",
      "[CV] units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=8, units3=16, units2=64, units1=26, schedule_decay=0.009000000000000001, rho=0.8311758068665892, optimizer=RMSprop, lr=1e-05, layers=1, epsilon=0.0001, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9423346068550754, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.046242, total=   6.0s\n",
      "[CV] units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.043369, total=   6.4s\n",
      "[CV] units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.038853, total=   6.6s\n",
      "[CV] units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=4, units3=8, units2=8, units1=26, schedule_decay=0.0035, rho=0.9021771605381883, optimizer=Adamax, lr=0.01, layers=1, epsilon=1e-06, epochs=100, decay=0.028, beta_2=0.926171906571784, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.030571, total=   6.9s\n",
      "[CV] units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu, score=0.046813, total=   7.2s\n",
      "[CV] units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu, score=0.039824, total=   7.1s\n",
      "[CV] units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=64, schedule_decay=0.0035, rho=0.8479222862390813, optimizer=Adamax, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.044, beta_2=0.9835223929985658, beta_1=0.9867252757344623, activation=relu, score=0.040520, total=   7.0s\n",
      "[CV] units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu, score=0.046647, total=   7.4s\n",
      "[CV] units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu, score=0.039531, total=   7.6s\n",
      "[CV] units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=4, units1=26, schedule_decay=0.007500000000000001, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.061, beta_2=0.9265849596843658, beta_1=0.9432879733220609, activation=relu, score=0.040520, total=   7.6s\n",
      "[CV] units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu, score=0.051958, total=   7.3s\n",
      "[CV] units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu, score=0.039372, total=   7.2s\n",
      "[CV] units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=32, units2=64, units1=64, schedule_decay=0.0045000000000000005, rho=0.8311758068665892, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.019, beta_2=0.9374027733163808, beta_1=0.9120492365301267, activation=relu, score=0.042080, total=   7.5s\n",
      "[CV] units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.048241, total=   7.4s\n",
      "[CV] units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.039300, total=   7.4s\n",
      "[CV] units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=64, units1=4, schedule_decay=0.001, rho=0.9430742129490844, optimizer=Adadelta, lr=0.001, layers=2, epsilon=1e-06, epochs=100, decay=0.058, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.040943, total=   7.4s\n",
      "[CV] units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu, score=0.047529, total=   7.6s\n",
      "[CV] units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu, score=0.039437, total=   7.6s\n",
      "[CV] units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=64, schedule_decay=0.002, rho=0.9237553382634431, optimizer=Adamax, lr=0.0001, layers=4, epsilon=1e-05, epochs=100, decay=0.062, beta_2=0.9374027733163808, beta_1=0.9792174674454335, activation=relu, score=0.042099, total=   9.1s\n",
      "[CV] units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu, score=0.046558, total=   7.5s\n",
      "[CV] units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu, score=0.039667, total=   7.6s\n",
      "[CV] units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=26, schedule_decay=0.0015, rho=0.9430742129490844, optimizer=Adadelta, lr=1e-05, layers=2, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.9835223929985658, beta_1=0.9120492365301267, activation=relu, score=0.040517, total=   7.6s\n",
      "[CV] units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.050616, total=   7.9s\n",
      "[CV] units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.053238, total=   8.0s\n",
      "[CV] units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=4, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.9164706059234075, optimizer=Adamax, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.015, beta_2=0.9506816237267246, beta_1=0.9270092329603724, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045317, total=   8.1s\n",
      "[CV] units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu, score=0.048442, total=   8.3s\n",
      "[CV] units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu, score=0.043410, total=   8.5s\n",
      "[CV] units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=8, units2=8, units1=8, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Nadam, lr=0.01, layers=3, epsilon=1e-05, epochs=100, decay=0.0, beta_2=0.9374027733163808, beta_1=0.9867252757344623, activation=relu, score=0.036915, total=   8.6s\n",
      "[CV] units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu, score=0.047276, total=   7.9s\n",
      "[CV] units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu, score=0.054122, total=   7.7s\n",
      "[CV] units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=8, units3=64, units2=16, units1=26, schedule_decay=0.004, rho=0.8311758068665892, optimizer=Adam, lr=1e-05, layers=1, epsilon=1e-08, epochs=100, decay=0.068, beta_2=0.976112535642155, beta_1=0.9270092329603724, activation=relu, score=0.055377, total=   7.9s\n",
      "[CV] units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039927, total=   8.3s\n",
      "[CV] units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.036414, total=   8.4s\n",
      "[CV] units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=4, units2=8, units1=26, schedule_decay=0.0065, rho=0.9237553382634431, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-06, epochs=100, decay=0.022, beta_2=0.9261750832355646, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.032863, total=   8.6s\n",
      "[CV] units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.052194, total=   8.2s\n",
      "[CV] units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.043004, total=   8.3s\n",
      "[CV] units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=16, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.9077619006529815, optimizer=SGD, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.083, beta_2=0.9146828892896675, beta_1=0.9792174674454335, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.042080, total=   7.9s\n",
      "[CV] units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.054693, total=   7.8s\n",
      "[CV] units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.041685, total=   7.8s\n",
      "[CV] units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=64, units2=32, units1=8, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=SGD, lr=1e-05, layers=2, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045862, total=   7.9s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu, score=0.046253, total=   8.3s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu, score=0.036896, total=   8.3s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.004, rho=0.8265195577225888, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.035, beta_2=0.936669600294371, beta_1=0.9867252757344623, activation=relu, score=0.040818, total=   8.7s\n",
      "[CV] units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu, score=0.050454, total=   8.6s\n",
      "[CV] units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu, score=0.040218, total=  10.1s\n",
      "[CV] units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=26, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=0.0001, layers=3, epsilon=1e-06, epochs=100, decay=0.052000000000000005, beta_2=0.936669600294371, beta_1=0.9432879733220609, activation=relu, score=0.039896, total=   8.7s\n",
      "[CV] units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu, score=0.053649, total=   8.3s\n",
      "[CV] units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu, score=0.045704, total=   8.3s\n",
      "[CV] units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=8, units3=16, units2=8, units1=26, schedule_decay=0.006, rho=0.8543654890157573, optimizer=Adagrad, lr=0.0001, layers=2, epsilon=1e-05, epochs=100, decay=0.013000000000000001, beta_2=0.9261750832355646, beta_1=0.9681596179201619, activation=relu, score=0.040245, total=   8.5s\n",
      "[CV] units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu, score=0.046647, total=   9.2s\n",
      "[CV] units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu, score=0.039151, total=   9.2s\n",
      "[CV] units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu \n",
      "[CV]  units4=32, units3=8, units2=4, units1=32, schedule_decay=0.009500000000000001, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=3, epsilon=0.0001, epochs=100, decay=0.049, beta_2=0.9195057588183283, beta_1=0.9306830100304931, activation=relu, score=0.038044, total=   9.1s\n",
      "[CV] units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.047025, total=   9.0s\n",
      "[CV] units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040761, total=   9.1s\n",
      "[CV] units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=64, units1=64, schedule_decay=0.002, rho=0.8274457922887202, optimizer=RMSprop, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.02, beta_2=0.9875983196541405, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.035026, total=   9.1s\n",
      "[CV] units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.056049, total=   9.1s\n",
      "[CV] units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.039520, total=   9.0s\n",
      "[CV] units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=16, units3=16, units2=8, units1=64, schedule_decay=0.009500000000000001, rho=0.8398919206556166, optimizer=Adagrad, lr=1e-05, layers=4, epsilon=1e-07, epochs=100, decay=0.074, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.040546, total=   9.2s\n",
      "[CV] units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu, score=0.054914, total=   9.0s\n",
      "[CV] units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu, score=0.044900, total=   9.2s\n",
      "[CV] units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=16, units3=4, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adadelta, lr=1e-05, layers=1, epsilon=1e-06, epochs=100, decay=0.094, beta_2=0.9101586361436318, beta_1=0.9423346068550754, activation=relu, score=0.041014, total=   9.1s\n",
      "[CV] units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.043829, total=   9.2s\n",
      "[CV] units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.038383, total=   9.4s\n",
      "[CV] units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=64, units2=8, units1=64, schedule_decay=0.006, rho=0.8171340077735547, optimizer=Adam, lr=0.01, layers=1, epsilon=1e-07, epochs=100, decay=0.096, beta_2=0.9261750832355646, beta_1=0.9867252757344623, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.031362, total=   9.3s\n",
      "[CV] units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040421, total=   9.9s\n",
      "[CV] units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.037666, total=  10.1s\n",
      "[CV] units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=64, units2=16, units1=4, schedule_decay=0.007500000000000001, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=4, epsilon=1e-05, epochs=100, decay=0.038, beta_2=0.9643806747145691, beta_1=0.9793775053748464, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040353, total=  10.0s\n",
      "[CV] units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.046985, total=   9.6s\n",
      "[CV] units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.043357, total=   9.6s\n",
      "[CV] units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=32, units2=8, units1=32, schedule_decay=0.0045000000000000005, rho=0.8265195577225888, optimizer=Adagrad, lr=0.001, layers=3, epsilon=1e-05, epochs=100, decay=0.031, beta_2=0.9914277888675106, beta_1=0.9866923845868506, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039712, total=   9.7s\n",
      "[CV] units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu, score=0.046913, total=   9.4s\n",
      "[CV] units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu, score=0.039557, total=   9.6s\n",
      "[CV] units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=16, units1=8, schedule_decay=0.004, rho=0.9284217213227293, optimizer=Adagrad, lr=0.01, layers=2, epsilon=1e-06, epochs=100, decay=0.084, beta_2=0.9729719183165639, beta_1=0.9120492365301267, activation=relu, score=0.041529, total=   9.3s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu, score=0.046647, total=   9.3s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu, score=0.041924, total=   9.3s\n",
      "[CV] units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu \n",
      "[CV]  units4=16, units3=64, units2=64, units1=32, schedule_decay=0.0025, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.023, beta_2=0.9265849596843658, beta_1=0.9120492365301267, activation=relu, score=0.040520, total=   9.4s\n",
      "[CV] units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu, score=0.046769, total=   9.9s\n",
      "[CV] units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu, score=0.040254, total=   9.7s\n",
      "[CV] units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=32, units1=64, schedule_decay=0.0045000000000000005, rho=0.8501565753108836, optimizer=Adamax, lr=0.001, layers=2, epsilon=1e-05, epochs=100, decay=0.061, beta_2=0.9506816237267246, beta_1=0.9793775053748464, activation=relu, score=0.040438, total=  11.4s\n",
      "[CV] units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.049669, total=  10.3s\n",
      "[CV] units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.039326, total=  10.3s\n",
      "[CV] units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu \n",
      "[CV]  units4=4, units3=16, units2=32, units1=64, schedule_decay=0.0035, rho=0.8254104998646793, optimizer=Nadam, lr=0.01, layers=2, epsilon=1e-05, epochs=100, decay=0.096, beta_2=0.9374027733163808, beta_1=0.9270092329603724, activation=relu, score=0.040520, total=  10.3s\n",
      "[CV] units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.044720, total=   9.8s\n",
      "[CV] units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.038182, total=   9.7s\n",
      "[CV] units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=4, units2=8, units1=64, schedule_decay=0.007500000000000001, rho=0.8311758068665892, optimizer=SGD, lr=0.001, layers=1, epsilon=0.0001, epochs=100, decay=0.046, beta_2=0.9914277888675106, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.036622, total=   9.7s\n",
      "[CV] units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu \n",
      "[CV]  units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu, score=0.048808, total=  10.2s\n",
      "[CV] units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu \n",
      "[CV]  units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu, score=0.039624, total=  10.3s\n",
      "[CV] units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu \n",
      "[CV]  units4=32, units3=16, units2=4, units1=64, schedule_decay=0.0085, rho=0.9164706059234075, optimizer=Adadelta, lr=0.001, layers=1, epsilon=1e-07, epochs=100, decay=0.01, beta_2=0.936669600294371, beta_1=0.9288119327973722, activation=relu, score=0.047984, total=  10.2s\n",
      "[CV] units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.040963, total=  10.2s\n",
      "[CV] units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039395, total=  10.4s\n",
      "[CV] units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=8, units2=16, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=RMSprop, lr=0.01, layers=3, epsilon=1e-09, epochs=100, decay=0.041, beta_2=0.976112535642155, beta_1=0.9711996704924956, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.036584, total=  10.5s\n",
      "[CV] units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045081, total=  11.1s\n",
      "[CV] units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039781, total=  11.3s\n",
      "[CV] units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=8, units2=4, units1=32, schedule_decay=0.0055000000000000005, rho=0.8171340077735547, optimizer=Nadam, lr=0.0001, layers=4, epsilon=1e-06, epochs=100, decay=0.007, beta_2=0.9446772765480753, beta_1=0.9288119327973722, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.034688, total=  11.4s\n",
      "[CV] units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu, score=0.057604, total=  10.0s\n",
      "[CV] units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu, score=0.044496, total=  10.0s\n",
      "[CV] units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu \n",
      "[CV]  units4=32, units3=64, units2=32, units1=4, schedule_decay=0.008, rho=0.8753061375171187, optimizer=SGD, lr=0.0001, layers=1, epsilon=1e-09, epochs=100, decay=0.059000000000000004, beta_2=0.9643806747145691, beta_1=0.9423346068550754, activation=relu, score=0.076119, total=  10.0s\n",
      "[CV] units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.046798, total=  11.5s\n",
      "[CV] units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.039429, total=  11.6s\n",
      "[CV] units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=64, units1=8, schedule_decay=0.004, rho=0.8666082263911343, optimizer=Nadam, lr=1e-05, layers=4, epsilon=1e-05, epochs=100, decay=0.098, beta_2=0.9819408717834255, beta_1=0.9792174674454335, activation=relu, score=0.040484, total=  11.7s\n",
      "[CV] units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045434, total=  10.6s\n",
      "[CV] units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.037070, total=  10.7s\n",
      "[CV] units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=32, units3=64, units2=8, units1=32, schedule_decay=0.008, rho=0.9284217213227293, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-08, epochs=100, decay=0.08, beta_2=0.9044671014559788, beta_1=0.9382659230432351, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.031233, total=  10.8s\n",
      "[CV] units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.044148, total=  11.2s\n",
      "[CV] units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.037788, total=  11.2s\n",
      "[CV] units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=4, units3=16, units2=4, units1=4, schedule_decay=0.009000000000000001, rho=0.8398919206556166, optimizer=RMSprop, lr=0.0001, layers=3, epsilon=1e-08, epochs=100, decay=0.081, beta_2=0.9875983196541405, beta_1=0.9870151785241231, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.038861, total=  11.1s\n",
      "[CV] units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045665, total=  11.3s\n",
      "[CV] units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039449, total=  11.3s\n",
      "[CV] units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=4, units2=8, units1=4, schedule_decay=0.0055000000000000005, rho=0.9471585230297452, optimizer=SGD, lr=0.0001, layers=4, epsilon=1e-08, epochs=100, decay=0.002, beta_2=0.926171906571784, beta_1=0.9432879733220609, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.039946, total=  11.6s\n",
      "[CV] units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu, score=0.046683, total=  11.7s\n",
      "[CV] units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu, score=0.047067, total=  11.6s\n",
      "[CV] units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu \n",
      "[CV]  units4=64, units3=64, units2=4, units1=64, schedule_decay=0.007, rho=0.9471585230297452, optimizer=Adam, lr=0.01, layers=2, epsilon=0.0001, epochs=100, decay=0.009000000000000001, beta_2=0.9355739559428804, beta_1=0.9866923845868506, activation=relu, score=0.040520, total=  11.7s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu, score=0.047229, total=  12.0s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu, score=0.039523, total=  11.9s\n",
      "[CV] units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu \n",
      "[CV]  units4=4, units3=32, units2=4, units1=26, schedule_decay=0.006, rho=0.9021771605381883, optimizer=Adamax, lr=0.001, layers=4, epsilon=1e-06, epochs=100, decay=0.046, beta_2=0.9835223929985658, beta_1=0.9681596179201619, activation=relu, score=0.040544, total=  14.3s\n",
      "[CV] units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu, score=0.050638, total=  11.7s\n",
      "[CV] units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu, score=0.038401, total=  11.9s\n",
      "[CV] units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu \n",
      "[CV]  units4=4, units3=16, units2=4, units1=8, schedule_decay=0.005, rho=0.8479222862390813, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-08, epochs=100, decay=0.023, beta_2=0.9506816237267246, beta_1=0.9432879733220609, activation=relu, score=0.038748, total=  12.0s\n",
      "[CV] units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.050222, total=  11.8s\n",
      "[CV] units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045223, total=  11.7s\n",
      "[CV] units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=64, units3=32, units2=16, units1=4, schedule_decay=0.0035, rho=0.9430742129490844, optimizer=SGD, lr=0.0001, layers=2, epsilon=1e-07, epochs=100, decay=0.062, beta_2=0.976112535642155, beta_1=0.9368767137216831, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.053700, total=  11.7s\n",
      "[CV] units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu \n",
      "[CV]  units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu, score=0.045540, total=  12.4s\n",
      "[CV] units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu, score=0.037166, total=  12.6s\n",
      "[CV] units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu \n",
      "[CV]  units4=16, units3=8, units2=32, units1=32, schedule_decay=0.004, rho=0.8576629684993036, optimizer=Adadelta, lr=0.01, layers=3, epsilon=0.0001, epochs=100, decay=0.001, beta_2=0.936669600294371, beta_1=0.9340763715814911, activation=relu, score=0.040628, total=  12.8s\n",
      "[CV] units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu, score=0.046256, total=  11.8s\n",
      "[CV] units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu, score=0.039662, total=  12.0s\n",
      "[CV] units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu \n",
      "[CV]  units4=32, units3=4, units2=4, units1=32, schedule_decay=0.0045000000000000005, rho=0.8070527841734456, optimizer=Adagrad, lr=0.01, layers=1, epsilon=0.0001, epochs=100, decay=0.092, beta_2=0.9044671014559788, beta_1=0.9793775053748464, activation=relu, score=0.040520, total=  12.1s\n",
      "[CV] units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.049416, total=  12.3s\n",
      "[CV] units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.039584, total=  12.4s\n",
      "[CV] units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu \n",
      "[CV]  units4=8, units3=8, units2=32, units1=4, schedule_decay=0.009000000000000001, rho=0.9237553382634431, optimizer=SGD, lr=0.01, layers=2, epsilon=1e-09, epochs=100, decay=0.066, beta_2=0.9446772765480753, beta_1=0.9867252757344623, activation=relu, score=0.040556, total=  12.2s\n",
      "[CV] units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.047197, total=  12.8s\n",
      "[CV] units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.054627, total=  12.6s\n",
      "[CV] units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8> \n",
      "[CV]  units4=16, units3=16, units2=64, units1=8, schedule_decay=0.008, rho=0.8666082263911343, optimizer=Adam, lr=0.001, layers=1, epsilon=1e-06, epochs=100, decay=0.089, beta_2=0.9506816237267246, beta_1=0.9306830100304931, activation=<keras.layers.advanced_activations.ELU object at 0x13259c0b8>, score=0.045064, total=  12.7s\n",
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 28.4min finished\n",
      "Elapsed: 28 minutes\n"
     ]
    }
   ],
   "source": [
    "start_timing()\n",
    "sweeper = random_sweep(\n",
    "    X_train, y_train, \n",
    "    model, param_grid,\n",
    "    scoring=compute_mae, \n",
    "    n_iter=75, n_jobs=1, \n",
    "    refit=False, cv=3, verbose=75)\n",
    "report_timing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Std</th>\n",
       "      <th>activation</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>layers</th>\n",
       "      <th>lr</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>rho</th>\n",
       "      <th>schedule_decay</th>\n",
       "      <th>units1</th>\n",
       "      <th>units2</th>\n",
       "      <th>units3</th>\n",
       "      <th>units4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.059</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.875306</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053150</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.051</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.928422</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.927009</td>\n",
       "      <td>0.976113</td>\n",
       "      <td>0.068</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052008</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.934076</td>\n",
       "      <td>0.904467</td>\n",
       "      <td>0.080</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.907762</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049727</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.927009</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.015</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.916471</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.936877</td>\n",
       "      <td>0.976113</td>\n",
       "      <td>0.062</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.943074</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>0.066</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.048971</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.983522</td>\n",
       "      <td>0.033</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.048960</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>0.910159</td>\n",
       "      <td>0.035</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.850157</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048956</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.089</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.866608</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.047442</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.943288</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.089</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.916471</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.910159</td>\n",
       "      <td>0.094</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.817134</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.046560</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.968160</td>\n",
       "      <td>0.926175</td>\n",
       "      <td>0.013</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.979217</td>\n",
       "      <td>0.914683</td>\n",
       "      <td>0.083</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.907762</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.045485</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.916471</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.045413</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>0.074</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.839892</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.044951</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.069</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.044764</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.009</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.979217</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.087</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.044499</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.912049</td>\n",
       "      <td>0.937403</td>\n",
       "      <td>0.019</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.043573</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.934076</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.008</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.043550</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.943288</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.052</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.839892</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.031</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>0.066</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.043197</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.927009</td>\n",
       "      <td>0.937403</td>\n",
       "      <td>0.096</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.825410</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.043044</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.912049</td>\n",
       "      <td>0.926585</td>\n",
       "      <td>0.023</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.807053</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.043039</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.979217</td>\n",
       "      <td>0.937403</td>\n",
       "      <td>0.062</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.089</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.902177</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.042944</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.937403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.902177</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.042849</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.927009</td>\n",
       "      <td>0.937403</td>\n",
       "      <td>0.058</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.943074</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.981941</td>\n",
       "      <td>0.016</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.041995</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.919506</td>\n",
       "      <td>0.084</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.943074</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.041878</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.956452</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.057</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.902177</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.926175</td>\n",
       "      <td>0.072</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.041702</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.943288</td>\n",
       "      <td>0.926172</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.041652</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.989534</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.054</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.928422</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>0.926585</td>\n",
       "      <td>0.058</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.041467</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.011</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.041342</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.035</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.041301</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.919506</td>\n",
       "      <td>0.049</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.866608</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.934076</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.857663</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.040961</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.971200</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.827446</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.979378</td>\n",
       "      <td>0.983522</td>\n",
       "      <td>0.036</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.040885</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.942335</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.060</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.826520</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.040716</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.922185</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.061</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.040501</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.979217</td>\n",
       "      <td>0.981941</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.916471</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.040407</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.989534</td>\n",
       "      <td>0.950682</td>\n",
       "      <td>0.075</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.866608</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.040281</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.987015</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.081</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.839892</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.936670</td>\n",
       "      <td>0.042</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.039870</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>0.007</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.817134</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.039861</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.971200</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.046</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.831176</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.039484</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.979378</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.038</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.971200</td>\n",
       "      <td>0.976113</td>\n",
       "      <td>0.041</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.947159</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.037942</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.938266</td>\n",
       "      <td>0.904467</td>\n",
       "      <td>0.080</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.928422</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.037881</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.926175</td>\n",
       "      <td>0.096</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.817134</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.037620</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.979378</td>\n",
       "      <td>0.926172</td>\n",
       "      <td>0.028</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.902177</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.037221</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.938266</td>\n",
       "      <td>0.910159</td>\n",
       "      <td>0.073</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.875306</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.036936</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.936877</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.003</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.902177</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.036485</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.944677</td>\n",
       "      <td>0.006</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.817134</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.036415</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>&lt;keras.layers.advanced_activations.ELU object ...</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.926175</td>\n",
       "      <td>0.022</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.923755</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score       Std                                         activation  \\\n",
       "0   0.059399  0.012973                                               relu   \n",
       "1   0.053150  0.010719                                               relu   \n",
       "2   0.052239  0.003560                                               relu   \n",
       "3   0.052008  0.008344  <keras.layers.advanced_activations.ELU object ...   \n",
       "4   0.049727  0.003295  <keras.layers.advanced_activations.ELU object ...   \n",
       "5   0.049717  0.003479  <keras.layers.advanced_activations.ELU object ...   \n",
       "6   0.049205  0.002626  <keras.layers.advanced_activations.ELU object ...   \n",
       "7   0.048971  0.008862  <keras.layers.advanced_activations.ELU object ...   \n",
       "8   0.048960  0.004574  <keras.layers.advanced_activations.ELU object ...   \n",
       "9   0.048956  0.004099  <keras.layers.advanced_activations.ELU object ...   \n",
       "10  0.047442  0.005423  <keras.layers.advanced_activations.ELU object ...   \n",
       "11  0.046974  0.005855                                               relu   \n",
       "12  0.046560  0.005503                                               relu   \n",
       "13  0.045784  0.004566  <keras.layers.advanced_activations.ELU object ...   \n",
       "14  0.045485  0.004149                                               relu   \n",
       "15  0.045413  0.007562                                               relu   \n",
       "16  0.044951  0.003489  <keras.layers.advanced_activations.ELU object ...   \n",
       "17  0.044764  0.003000                                               relu   \n",
       "18  0.044636  0.003584                                               relu   \n",
       "19  0.044499  0.005409                                               relu   \n",
       "20  0.043573  0.002318                                               relu   \n",
       "21  0.043550  0.004903                                               relu   \n",
       "22  0.043366  0.002969  <keras.layers.advanced_activations.ELU object ...   \n",
       "23  0.043210  0.004424                                               relu   \n",
       "24  0.043197  0.004620                                               relu   \n",
       "25  0.043044  0.002621                                               relu   \n",
       "26  0.043039  0.003368                                               relu   \n",
       "27  0.043004  0.003781                                               relu   \n",
       "28  0.042944  0.004719                                               relu   \n",
       "29  0.042849  0.003886                                               relu   \n",
       "..       ...       ...                                                ...   \n",
       "45  0.042006  0.004157                                               relu   \n",
       "46  0.041995  0.002793                                               relu   \n",
       "47  0.041878  0.003090                                               relu   \n",
       "48  0.041718  0.003378                                               relu   \n",
       "49  0.041702  0.002820  <keras.layers.advanced_activations.ELU object ...   \n",
       "50  0.041652  0.003238                                               relu   \n",
       "51  0.041615  0.003592                                               relu   \n",
       "52  0.041467  0.003437                                               relu   \n",
       "53  0.041342  0.003837                                               relu   \n",
       "54  0.041301  0.003821                                               relu   \n",
       "55  0.041129  0.003436                                               relu   \n",
       "56  0.040961  0.004900  <keras.layers.advanced_activations.ELU object ...   \n",
       "57  0.040944  0.003376  <keras.layers.advanced_activations.ELU object ...   \n",
       "58  0.040885  0.003932                                               relu   \n",
       "59  0.040716  0.005348                                               relu   \n",
       "60  0.040501  0.004455                                               relu   \n",
       "61  0.040407  0.004557                                               relu   \n",
       "62  0.040281  0.002780  <keras.layers.advanced_activations.ELU object ...   \n",
       "63  0.040057  0.006297  <keras.layers.advanced_activations.ELU object ...   \n",
       "64  0.039870  0.004243  <keras.layers.advanced_activations.ELU object ...   \n",
       "65  0.039861  0.003508  <keras.layers.advanced_activations.ELU object ...   \n",
       "66  0.039484  0.001283  <keras.layers.advanced_activations.ELU object ...   \n",
       "67  0.038988  0.001812  <keras.layers.advanced_activations.ELU object ...   \n",
       "68  0.037942  0.005828  <keras.layers.advanced_activations.ELU object ...   \n",
       "69  0.037881  0.005103  <keras.layers.advanced_activations.ELU object ...   \n",
       "70  0.037620  0.005299  <keras.layers.advanced_activations.ELU object ...   \n",
       "71  0.037221  0.006431  <keras.layers.advanced_activations.ELU object ...   \n",
       "72  0.036936  0.005047  <keras.layers.advanced_activations.ELU object ...   \n",
       "73  0.036485  0.005232  <keras.layers.advanced_activations.ELU object ...   \n",
       "74  0.036415  0.002884  <keras.layers.advanced_activations.ELU object ...   \n",
       "\n",
       "      beta_1    beta_2  decay  epochs       epsilon  layers       lr  \\\n",
       "0   0.942335  0.964381  0.059     100  1.000000e-09       1  0.00010   \n",
       "1   0.942335  0.950682  0.051     100  1.000000e-08       1  0.00001   \n",
       "2   0.927009  0.976113  0.068     100  1.000000e-08       1  0.00001   \n",
       "3   0.934076  0.904467  0.080     100  1.000000e-05       1  0.00001   \n",
       "4   0.927009  0.950682  0.015     100  1.000000e-05       4  0.00001   \n",
       "5   0.936877  0.976113  0.062     100  1.000000e-07       2  0.00010   \n",
       "6   0.942335  0.944677  0.066     100  1.000000e-04       1  0.00001   \n",
       "7   0.987881  0.983522  0.033     100  1.000000e-08       3  0.00001   \n",
       "8   0.928812  0.910159  0.035     100  1.000000e-09       2  0.00100   \n",
       "9   0.930683  0.950682  0.089     100  1.000000e-06       1  0.00100   \n",
       "10  0.943288  0.936670  0.089     100  1.000000e-06       2  0.00001   \n",
       "11  0.942335  0.910159  0.094     100  1.000000e-06       1  0.00001   \n",
       "12  0.968160  0.926175  0.013     100  1.000000e-05       2  0.00010   \n",
       "13  0.979217  0.914683  0.083     100  1.000000e-06       3  0.00010   \n",
       "14  0.928812  0.936670  0.010     100  1.000000e-07       1  0.00100   \n",
       "15  0.986725  0.944677  0.074     100  1.000000e-07       4  0.00001   \n",
       "16  0.930683  0.991428  0.069     100  1.000000e-04       3  0.00100   \n",
       "17  0.986692  0.935574  0.009     100  1.000000e-04       2  0.01000   \n",
       "18  0.979217  0.987598  0.087     100  1.000000e-08       1  0.00010   \n",
       "19  0.912049  0.937403  0.019     100  1.000000e-06       2  0.00001   \n",
       "20  0.934076  0.987598  0.008     100  1.000000e-04       2  0.00001   \n",
       "21  0.943288  0.936670  0.052     100  1.000000e-06       3  0.00010   \n",
       "22  0.986692  0.991428  0.031     100  1.000000e-05       3  0.00100   \n",
       "23  0.986725  0.944677  0.066     100  1.000000e-09       2  0.01000   \n",
       "24  0.927009  0.937403  0.096     100  1.000000e-05       2  0.01000   \n",
       "25  0.912049  0.926585  0.023     100  1.000000e-04       2  0.01000   \n",
       "26  0.979217  0.937403  0.062     100  1.000000e-05       4  0.00010   \n",
       "27  0.930683  0.964381  0.089     100  1.000000e-06       3  0.00001   \n",
       "28  0.986725  0.937403  0.000     100  1.000000e-05       3  0.01000   \n",
       "29  0.927009  0.937403  0.058     100  1.000000e-06       2  0.00100   \n",
       "..       ...       ...    ...     ...           ...     ...      ...   \n",
       "45  0.987881  0.981941  0.016     100  1.000000e-04       2  0.00100   \n",
       "46  0.942335  0.919506  0.084     100  1.000000e-08       3  0.01000   \n",
       "47  0.956452  0.935574  0.057     100  1.000000e-06       2  0.00010   \n",
       "48  0.986692  0.926175  0.072     100  1.000000e-04       3  0.00010   \n",
       "49  0.943288  0.926172  0.002     100  1.000000e-08       4  0.00010   \n",
       "50  0.989534  0.991428  0.054     100  1.000000e-07       3  0.00100   \n",
       "51  0.928812  0.926585  0.058     100  1.000000e-07       2  0.01000   \n",
       "52  0.942335  0.987598  0.011     100  1.000000e-08       1  0.00100   \n",
       "53  0.986725  0.936670  0.035     100  1.000000e-04       2  0.01000   \n",
       "54  0.930683  0.919506  0.049     100  1.000000e-04       3  0.00100   \n",
       "55  0.934076  0.936670  0.001     100  1.000000e-04       3  0.01000   \n",
       "56  0.971200  0.987598  0.020     100  1.000000e-07       4  0.00001   \n",
       "57  0.979378  0.983522  0.036     100  1.000000e-06       4  0.00100   \n",
       "58  0.942335  0.936670  0.060     100  1.000000e-06       3  0.00100   \n",
       "59  0.922185  0.950682  0.061     100  1.000000e-05       2  0.01000   \n",
       "60  0.979217  0.981941  0.010     100  1.000000e-04       2  0.01000   \n",
       "61  0.989534  0.950682  0.075     100  1.000000e-09       2  0.00100   \n",
       "62  0.987015  0.987598  0.081     100  1.000000e-08       3  0.00010   \n",
       "63  0.986725  0.936670  0.042     100  1.000000e-08       1  0.01000   \n",
       "64  0.928812  0.944677  0.007     100  1.000000e-06       4  0.00010   \n",
       "65  0.971200  0.991428  0.046     100  1.000000e-04       1  0.00100   \n",
       "66  0.979378  0.964381  0.038     100  1.000000e-05       4  0.01000   \n",
       "67  0.971200  0.976113  0.041     100  1.000000e-09       3  0.01000   \n",
       "68  0.938266  0.904467  0.080     100  1.000000e-08       2  0.01000   \n",
       "69  0.986725  0.926175  0.096     100  1.000000e-07       1  0.01000   \n",
       "70  0.979378  0.926172  0.028     100  1.000000e-06       1  0.01000   \n",
       "71  0.938266  0.910159  0.073     100  1.000000e-04       1  0.01000   \n",
       "72  0.936877  0.935574  0.003     100  1.000000e-07       4  0.00100   \n",
       "73  0.930683  0.944677  0.006     100  1.000000e-04       1  0.01000   \n",
       "74  0.986692  0.926175  0.022     100  1.000000e-06       4  0.01000   \n",
       "\n",
       "   optimizer       rho  schedule_decay  units1  units2  units3  units4  \n",
       "0        SGD  0.875306          0.0080       4      32      64      32  \n",
       "1       Adam  0.928422          0.0065       8      64       4      32  \n",
       "2       Adam  0.831176          0.0040      26      16      64       8  \n",
       "3    Adagrad  0.907762          0.0070       4      32      32       4  \n",
       "4     Adamax  0.916471          0.0090       4       4       4       4  \n",
       "5        SGD  0.943074          0.0035       4      16      32      64  \n",
       "6    RMSprop  0.831176          0.0090      26      64      16       8  \n",
       "7       Adam  0.947159          0.0050      32      32      32       8  \n",
       "8   Adadelta  0.850157          0.0030       4       4      64      16  \n",
       "9       Adam  0.866608          0.0080       8      64      16      16  \n",
       "10       SGD  0.916471          0.0085       8      32      64      16  \n",
       "11  Adadelta  0.817134          0.0060      64       8       4      16  \n",
       "12   Adagrad  0.854365          0.0060      26       8      16       8  \n",
       "13       SGD  0.907762          0.0095      32       4      16      64  \n",
       "14  Adadelta  0.916471          0.0085      64       4      16      32  \n",
       "15   Adagrad  0.839892          0.0095      64       8      16      16  \n",
       "16  Adadelta  0.831176          0.0085       8       8      16      64  \n",
       "17      Adam  0.947159          0.0070      64       4      64      64  \n",
       "18   Adagrad  0.947159          0.0090      64      16      16      64  \n",
       "19  Adadelta  0.831176          0.0045      64      64      32      64  \n",
       "20   RMSprop  0.923755          0.0085      32      16      32      64  \n",
       "21   Adagrad  0.839892          0.0095      26      64      64      16  \n",
       "22   Adagrad  0.826520          0.0045      32       8      32       4  \n",
       "23       SGD  0.923755          0.0090       4      32       8       8  \n",
       "24     Nadam  0.825410          0.0035      64      32      16       4  \n",
       "25   Adagrad  0.807053          0.0025      32      64      64      16  \n",
       "26    Adamax  0.923755          0.0020      64       8      16       8  \n",
       "27       SGD  0.902177          0.0055       8      16      32       4  \n",
       "28     Nadam  0.902177          0.0060       8       8       8      16  \n",
       "29  Adadelta  0.943074          0.0010       4      64      64       8  \n",
       "..       ...       ...             ...     ...     ...     ...     ...  \n",
       "45   RMSprop  0.826520          0.0080       8       4       8      32  \n",
       "46       SGD  0.943074          0.0020       8      64       4       8  \n",
       "47     Nadam  0.902177          0.0095      26      16      64      16  \n",
       "48      Adam  0.854365          0.0080       8      64      16      64  \n",
       "49       SGD  0.947159          0.0055       4       8       4      16  \n",
       "50    Adamax  0.928422          0.0065      32       8      32      64  \n",
       "51   RMSprop  0.854365          0.0025       4       8      16      16  \n",
       "52       SGD  0.947159          0.0065      32       4      32      16  \n",
       "53      Adam  0.826520          0.0040      26       4      32       4  \n",
       "54      Adam  0.866608          0.0095      32       4       8      32  \n",
       "55  Adadelta  0.857663          0.0040      32      32       8      16  \n",
       "56   RMSprop  0.827446          0.0020      64      64      64      32  \n",
       "57   Adagrad  0.831176          0.0030      64       4      64       4  \n",
       "58      Adam  0.826520          0.0045      32      64      64      16  \n",
       "59      Adam  0.854365          0.0025      26       8      32       4  \n",
       "60   RMSprop  0.916471          0.0025      32       8      16      64  \n",
       "61     Nadam  0.866608          0.0035       4      64       8      32  \n",
       "62   RMSprop  0.839892          0.0090       4       4      16       4  \n",
       "63   RMSprop  0.923755          0.0075      64       4      16      16  \n",
       "64     Nadam  0.817134          0.0055      32       4       8      16  \n",
       "65       SGD  0.831176          0.0075      64       8       4      32  \n",
       "66   RMSprop  0.947159          0.0075       4      16      64      64  \n",
       "67   RMSprop  0.947159          0.0055       4      16       8      32  \n",
       "68       SGD  0.928422          0.0080      32       8      64      32  \n",
       "69      Adam  0.817134          0.0060      64       8      64       4  \n",
       "70    Adamax  0.902177          0.0035      26       8       8       4  \n",
       "71    Adamax  0.875306          0.0085      26      64       4       8  \n",
       "72   Adagrad  0.902177          0.0075      26      32      16       4  \n",
       "73      Adam  0.817134          0.0060      64       8       4      64  \n",
       "74   RMSprop  0.923755          0.0065      26       8       4      64  \n",
       "\n",
       "[75 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sweep_stats(sweeper)\n",
    "# FILE_PATH = os.path.join(CWD, \"../results/best_params/forecasting/tCNN_hourlyData-25percent_SEEDFEATS-DP-RH-WindGust-Speed_Resp-ForeCast-LW-8-2-VWC_H1_Rw120_W360_Tune_run1.csv\")\n",
    "# results.to_csv(FILE_PATH)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 1\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.023253 ± 0.000450', 'Testing MAE 0.032841 ± 0.001472')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 2\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.029665 ± 0.000799', 'Testing MAE 0.032440 ± 0.001228')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.035279 ± 0.000925', 'Testing MAE 0.040454 ± 0.001765')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 4\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.033906 ± 0.000610', 'Testing MAE 0.037391 ± 0.000182')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 5\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.032930 ± 0.000640', 'Testing MAE 0.035935 ± 0.000297')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 6\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.034609 ± 0.000140', 'Testing MAE 0.037890 ± 0.000216')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 7\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.033881 ± 0.000325', 'Testing MAE 0.038162 ± 0.001530')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 8\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.027999 ± 0.000978', 'Testing MAE 0.034873 ± 0.003267')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 9\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.027544 ± 0.000484', 'Testing MAE 0.036058 ± 0.001192')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.038170 ± 0.000080', 'Testing MAE 0.042772 ± 0.001089')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    RUN = i+1\n",
    "    print('Best Run Num: {0}'.format(RUN))\n",
    "    params = results.iloc[-RUN,2:].to_dict()\n",
    "    # params\n",
    "\n",
    "    ### Testing the best params\n",
    "\n",
    "    np.random.seed(84)\n",
    "    tf.set_random_seed(84)\n",
    "\n",
    "    params['epochs'] = 100\n",
    "\n",
    "    train_results, test_results = [], []\n",
    "    ITERATIONS=3\n",
    "    VERBOSE=0\n",
    "\n",
    "    # params\n",
    "\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=25, min_lr=1e-08, \n",
    "                                  mode='auto', verbose=1)\n",
    "\n",
    "    for i in range(ITERATIONS):\n",
    "        model = KerasRegressor(build_fn=create_NN_model, shuffle=True, verbose=VERBOSE, **params)\n",
    "        history = model.fit(X_train, y_train, verbose=VERBOSE, validation_split = 0.15, callbacks=[reduce_lr])\n",
    "#         history = model.fit(X_train, y_train, verbose=VERBOSE, validation_split = None)\n",
    "        train_results.append(test_mae(model)[0])\n",
    "        test_results.append(test_mae(model)[1])\n",
    "    report(train_results, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 1\n",
      "0\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "1\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "2\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "3\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "4\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "5\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "6\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "7\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "8\n",
      "9\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "10\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "11\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "12\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "13\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "14\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "15\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "16\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "17\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "18\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "19\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.023763 ± 0.001320', 'Testing MAE 0.032601 ± 0.001573')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN = 1\n",
    "print('Best Run Num: {0}'.format(RUN))\n",
    "params = results.iloc[-RUN,2:].to_dict()\n",
    "\n",
    "### Testing the best params\n",
    "\n",
    "np.random.seed(84)\n",
    "tf.set_random_seed(84)\n",
    "\n",
    "params['epochs'] = 100\n",
    "\n",
    "train_results, test_results = [], []\n",
    "ITERATIONS=20\n",
    "VERBOSE=0\n",
    "\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=25, min_lr=1e-08, \n",
    "                              mode='auto', verbose=0)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    print(i)\n",
    "    model = KerasRegressor(build_fn=create_NN_model, shuffle=True, verbose=VERBOSE, **params)\n",
    "    history = model.fit(X_train, y_train, verbose=VERBOSE, validation_split = 0.15, callbacks=[reduce_lr])\n",
    "#         history = model.fit(X_train, y_train, verbose=VERBOSE, validation_split = None)\n",
    "    train_results.append(test_mae(model)[0])\n",
    "    test_results.append(test_mae(model)[1])\n",
    "report(train_results, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df_NN = pd.DataFrame({'mae_NN': test_results})\n",
    "mae_df_NN.to_csv('../data/results_data/results_df_NN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = 1\n",
    "\n",
    "params = results.iloc[-RUN,2:].to_dict()\n",
    "\n",
    "### Testing the best params\n",
    "\n",
    "np.random.seed(84)\n",
    "tf.set_random_seed(84)\n",
    "\n",
    "params['epochs'] = 100\n",
    "\n",
    "train_results, test_results = [], []\n",
    "ITERATIONS=3\n",
    "VERBOSE=0\n",
    "\n",
    "# params\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-08, mode='auto', verbose=1)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    model = KerasRegressor(build_fn=create_NN_model, shuffle=True, verbose=VERBOSE, **params)\n",
    "#     history = model.fit(train_X, train_y, verbose=VERBOSE, validation_split = 0.15, callbacks=[early_stopping])\n",
    "    history = model.fit(X_train, y_train, verbose=VERBOSE, validation_split = None)\n",
    "    train_results.append(test_mae(model)[0])\n",
    "    test_results.append(test_mae(model)[1])\n",
    "    report(train_results, test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

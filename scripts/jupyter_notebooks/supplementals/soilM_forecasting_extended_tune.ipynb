{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Input, Dense, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Flatten, GRU, LSTM\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import tensorflow as tf\n",
    "from pymlx import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windowed(dataset, seq_length, horizon, feat_cols, resp_cols, region_col, split=0.2, resp_width=0,\n",
    "                        predict_current=False):\n",
    "    \"\"\"\n",
    "    This function takes data and creates a windowed dataframe to be used in time-series analysis. \n",
    "    dataset: [panda df] the raw dataframe that a time series windowed df will be created from\n",
    "    seq_length: [int] the sequence length, the amount of time to be used to perform the \n",
    "                time-series analysis\n",
    "    horizon: [int] how far into the future you wish to predict\n",
    "    feat_cols: [list] a list of column names that make up the feature space\n",
    "    resp_cols: [list] a list of column names that make up the response\n",
    "    region_col: [str] the name of the column that different time-series will be created on, i.e. \n",
    "                different regions that contain\n",
    "                independent time-series.\n",
    "    split: [float] A percent split for the test set, i.e. 0.2 equals a 80/20 split for the \n",
    "                train/test sets.\n",
    "    resp_width: [int] If you want to predict out to a set distance you set the horizon to that \n",
    "                    time point and this value to 0, however if you want to predict every value \n",
    "                    between let's say now and some point in the future you set horizon to 1 and\n",
    "                    the resp_width to that point. The algorithm will then predict every time point.\n",
    "    predict_current: [bool] horizon needs to be set to 1 for this to work. This will predict at \n",
    "                    the current time so if there is a sequence length of 2 instead of forecasting \n",
    "                    out the horizon length, the model\n",
    "                    will predict at the current time.\n",
    "    \"\"\"\n",
    "\n",
    "    if ((predict_current) and (horizon is not 1)):\n",
    "        raise ValueError('If predict_current is set to True, then Horizon must be set to 1.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if (any(dataset[feat_cols + resp_cols].isnull().sum()) != 0):\n",
    "        raise ValueError('There is missing data in at least one of the columns supplied in keep_cols. \\\n",
    "                         Please impute this missing data as needed.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # check to see if there are same features in both the response and the features list\n",
    "    resp_and_feats = [var for var in feat_cols if var in resp_cols]\n",
    "\n",
    "    regions = list(dataset[region_col].unique())\n",
    "    big_dict = {}\n",
    "\n",
    "    for i in range(len(regions)):\n",
    "        big_dict.update({regions[i]: dataset[dataset[region_col] == regions[i]]})\n",
    "    features = len(feat_cols)\n",
    "    response = len(resp_cols)\n",
    "    if resp_width == 0:\n",
    "        train_X_all, test_X_all = np.empty((0, seq_length, features)), np.empty((0, seq_length, features))\n",
    "        train_y_all, test_y_all = np.empty((0, response)), np.empty((0, response))\n",
    "    else:\n",
    "        train_X_all, test_X_all = np.empty((0, sequence_length, features)), np.empty((0, sequence_length, features))\n",
    "        train_y_all, test_y_all = np.empty((0, resp_width, response)), np.empty((0, resp_width, response))\n",
    "\n",
    "    for region in regions:\n",
    "        big_dict[region] = big_dict[region][resp_cols + feat_cols]\n",
    "        if resp_and_feats:\n",
    "            big_dict[region] = big_dict[region].loc[:, ~big_dict[region].columns.duplicated()]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        length = len(big_dict[region])\n",
    "        test_length = int(length * split)  # 20% test set\n",
    "\n",
    "        df_x = big_dict[region][feat_cols]\n",
    "        df_y = big_dict[region][resp_cols]\n",
    "        ts_x = df_x.values\n",
    "        ts_y = df_y.values\n",
    "\n",
    "        train_length = length - test_length\n",
    "\n",
    "        train_X, train_y, test_X, test_y = [], [], [], []\n",
    "\n",
    "        if (predict_current):\n",
    "            z = 2\n",
    "            q = 1\n",
    "        else:\n",
    "            z = 1\n",
    "            q = 0\n",
    "\n",
    "        if (resp_width != 0):\n",
    "            for i in range(train_length - sequence_length - horizon - resp_width):\n",
    "                train_X.append(ts_x[i:i + sequence_length])\n",
    "                train_y.append(ts_y[i + sequence_length + horizon - z:i + sequence_length + horizon - z + resp_width])\n",
    "            for i in range(-test_length, -resp_width):\n",
    "                test_X.append(ts_x[i - sequence_length - horizon + 1:i - horizon + 1])\n",
    "                test_y.append(ts_y[i - q:i - q + (resp_width)])\n",
    "\n",
    "        else:\n",
    "            for i in range(train_length - seq_length - horizon):\n",
    "                train_X.append(ts_x[i:i + seq_length])\n",
    "                train_y.append(ts_y[i + seq_length + horizon - z])\n",
    "            for i in range(-test_length, 0):\n",
    "                test_X.append(ts_x[i - seq_length - horizon + 1:i - horizon + 1])\n",
    "                test_y.append(ts_y[i - q])\n",
    "\n",
    "        train_X, train_y = np.array(train_X), np.array(train_y)\n",
    "        test_X, test_y = np.array(test_X), np.array(test_y)\n",
    "\n",
    "        train_X_all = np.append(train_X_all, train_X, axis=0)\n",
    "        test_X_all = np.append(test_X_all, test_X, axis=0)\n",
    "        train_y_all = np.append(train_y_all, train_y, axis=0)\n",
    "        test_y_all = np.append(test_y_all, test_y, axis=0)\n",
    "\n",
    "    # normalize\n",
    "    mean_x = train_X_all.mean(0)\n",
    "    std_x = train_X_all.std(0)\n",
    "\n",
    "    train_X = (train_X_all - mean_x) / std_x\n",
    "    test_X = (test_X_all - mean_x) / std_x\n",
    "    train_X = train_X.astype('float32')\n",
    "    test_X = test_X.astype('float32')\n",
    "\n",
    "    mean_y = train_y_all.mean(0)\n",
    "    std_y = train_y_all.std(0)\n",
    "\n",
    "    train_y = (train_y_all - mean_y) / std_y\n",
    "    test_y = (test_y_all - mean_y) / std_y\n",
    "    train_y = train_y.astype('float32')\n",
    "    test_y = test_y.astype('float32')\n",
    "\n",
    "    if resp_width != 0:\n",
    "        std_y = std_y.ravel()\n",
    "        mean_y = mean_y.ravel()\n",
    "        train_y = train_y.reshape(train_y.shape[0], train_y.shape[1] * response)\n",
    "        test_y = test_y.reshape(test_y.shape[0], test_y.shape[1] * response)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print('train_X shape:', np.shape(train_X))\n",
    "    print('train_y shape:', np.shape(train_y))\n",
    "    print('test_X shape:', np.shape(test_X))\n",
    "    print('test_y shape:', np.shape(test_y))\n",
    "\n",
    "    return train_X, test_X, train_y, test_y, mean_x, std_x, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def compute_mape_minMax(model, x, y):\n",
    "    forecasts = model.predict(x, batch_size=len(x))\n",
    "    forecasts = (forecasts *  (max_soilT - min_soilT)) + min_soilT\n",
    "    y_denom = (y * (max_soilT - min_soilT)) + min_soilT\n",
    "    return np.mean(np.abs((y_denom - forecasts) / y_denom))\n",
    "\n",
    "\n",
    "def compute_mape_centerScale(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "#     forecasts = forecasts.reshape(forecasts.shape[0],dense)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    sub_result = np.abs((y_denom - forecasts) / y_denom )\n",
    "    # remove rows that are divided by 0 or a very small number\n",
    "    idxinf = np.where(sub_result == np.inf)\n",
    "    idx = np.where(sub_result > 1)\n",
    "    total_remove = len(idxinf[0]) + len(idx[0])\n",
    "    #print('Removed %f percent of the data, a total of %d rows.'% (((total_remove/len(forecasts))*100), total_remove))\n",
    "    sub_result = np.delete(sub_result, idxinf[0],0)\n",
    "    sub_result = np.delete(sub_result, idx[0], 0)\n",
    "    result = (np.mean(sub_result))\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_mae(model, x, y):\n",
    "    forecasts = model.predict(x)\n",
    "#     forecasts = forecasts.reshape(forecasts.shape[0],dense)\n",
    "    forecasts = (forecasts * std_y) + mean_y\n",
    "    y_denom = (y * std_y) + mean_y\n",
    "    result = mean_absolute_error(y_pred=forecasts, y_true=y_denom)\n",
    "    return result\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    # print('Train Mean Absolute Percentage Error (MAPE): {0:.3f}'.format(compute_mape_centerScale(model, train_X, train_y)))\n",
    "    # print('Test Mean Absolute Percentage Error (MAPE): {0:.3f}'.format(compute_mape_centerScale(model, test_X, test_y)))\n",
    "    return(compute_mape_centerScale(model, train_X, train_y), compute_mape_centerScale(model, test_X, test_y))\n",
    "\n",
    "def test_mae(model):\n",
    "    yhat_train = model.predict(train_X)\n",
    "    yhat_test = model.predict(test_X)\n",
    "    return(compute_mae(model, train_X, train_y), compute_mae(model, test_X, test_y))\n",
    "\n",
    "\n",
    "def report(train, test):\n",
    "    train_mean = np.asarray(train).mean()\n",
    "    train_std = np.asarray(train).std()\n",
    "    test_mean = np.asarray(test).mean()\n",
    "    test_std = np.asarray(test).std()\n",
    "    train = str('Training MAE %f ± %f'% (train_mean, train_std))\n",
    "    test = str('Testing MAE %f ± %f'% (test_mean, test_std))\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>field</th>\n",
       "      <th>soilM_avg</th>\n",
       "      <th>imputed</th>\n",
       "      <th>precip.cm</th>\n",
       "      <th>tair.C</th>\n",
       "      <th>rh.pct</th>\n",
       "      <th>wind_sp.m_per_s</th>\n",
       "      <th>irradiance.w_per_m.2</th>\n",
       "      <th>average_sand</th>\n",
       "      <th>average_silt</th>\n",
       "      <th>average_clay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.305329</td>\n",
       "      <td>0.305329</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.816667</td>\n",
       "      <td>39.958333</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>252.708333</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.307472</td>\n",
       "      <td>0.307472</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>47.958333</td>\n",
       "      <td>8.145833</td>\n",
       "      <td>217.375000</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.306836</td>\n",
       "      <td>0.306836</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>130.291667</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.305759</td>\n",
       "      <td>0.305759</td>\n",
       "      <td>1.106</td>\n",
       "      <td>7.920833</td>\n",
       "      <td>87.125000</td>\n",
       "      <td>3.370833</td>\n",
       "      <td>73.583333</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>AES</td>\n",
       "      <td>0.305109</td>\n",
       "      <td>0.305109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.412500</td>\n",
       "      <td>65.958333</td>\n",
       "      <td>6.962500</td>\n",
       "      <td>252.916667</td>\n",
       "      <td>14.891866</td>\n",
       "      <td>60.796955</td>\n",
       "      <td>24.311179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date field  soilM_avg   imputed  precip.cm     tair.C     rh.pct  \\\n",
       "0  2014-04-14   AES   0.305329  0.305329      0.000  10.816667  39.958333   \n",
       "1  2014-04-15   AES   0.307472  0.307472      0.000   8.850000  47.958333   \n",
       "2  2014-04-16   AES   0.306836  0.306836      0.000   7.625000  67.125000   \n",
       "3  2014-04-17   AES   0.305759  0.305759      1.106   7.920833  87.125000   \n",
       "4  2014-04-18   AES   0.305109  0.305109      0.000   6.412500  65.958333   \n",
       "\n",
       "   wind_sp.m_per_s  irradiance.w_per_m.2  average_sand  average_silt  \\\n",
       "0         3.125000            252.708333     14.891866     60.796955   \n",
       "1         8.145833            217.375000     14.891866     60.796955   \n",
       "2         2.333333            130.291667     14.891866     60.796955   \n",
       "3         3.370833             73.583333     14.891866     60.796955   \n",
       "4         6.962500            252.916667     14.891866     60.796955   \n",
       "\n",
       "   average_clay  \n",
       "0     24.311179  \n",
       "1     24.311179  \n",
       "2     24.311179  \n",
       "3     24.311179  \n",
       "4     24.311179  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "FILE_PATH = os.path.join(CWD, \"../data/time_series_soilM_averaged_50percent_tuning.csv\")\n",
    "# FILE_PATH = os.path.join(CWD, \"../data/time_series_soilM_averaged.csv\")\n",
    "dataset = pd.read_csv(FILE_PATH)\n",
    "dataset.head()\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])\n",
    "dataset = dataset.set_index(['date'])\n",
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'field', 'soilM_avg', 'imputed', 'precip.cm', 'tair.C',\n",
       "       'rh.pct', 'wind_sp.m_per_s', 'irradiance.w_per_m.2', 'average_sand',\n",
       "       'average_silt', 'average_clay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                     0\n",
       "field                    0\n",
       "soilM_avg               18\n",
       "imputed                  0\n",
       "precip.cm                0\n",
       "tair.C                   0\n",
       "rh.pct                   0\n",
       "wind_sp.m_per_s          0\n",
       "irradiance.w_per_m.2     0\n",
       "average_sand             0\n",
       "average_silt             0\n",
       "average_clay             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_cols = ['imputed']\n",
    "feat_cols = ['precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s', 'irradiance.w_per_m.2', 'average_clay',\n",
    "       'average_sand', 'average_silt']\n",
    "keep_cols = resp_cols + feat_cols\n",
    "\n",
    "sequence_length = 30\n",
    "horizon = 14\n",
    "resp_width = 0\n",
    "dense = len(resp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Windowed DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (2520, 30, 8)\n",
      "train_y shape: (2520, 1)\n",
      "test_X shape: (681, 30, 8)\n",
      "test_y shape: (681, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y, mean_x, std_x, mean_y, std_y = make_windowed(dataset=dataset, \n",
    "                                                                                     seq_length=sequence_length,\n",
    "                                                                                     horizon=horizon,\n",
    "                                                                                     resp_cols=resp_cols,\n",
    "                                                                                     feat_cols=feat_cols,\n",
    "                                                                                     region_col='field',\n",
    "                                                                                     resp_width=resp_width,\n",
    "                                                                                     predict_current=False)\n",
    "dim = train_X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model for Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(84)\n",
    "tf.set_random_seed(84)\n",
    "\n",
    "def create_tCNN_model(max_meanPool_1=1,\n",
    "                      max_meanPool_2=1,\n",
    "                      max_meanPool_3=1,\n",
    "                      max_meanPool_4=1,\n",
    "                      max_meanPool_5=1,\n",
    "                      max_meanPool_6=1,\n",
    "                      filters1=32,\n",
    "                      filters2=32,\n",
    "                      filters3=32,\n",
    "                      filters4=32,\n",
    "                      filters5=32,\n",
    "                      filters6=32,\n",
    "                      filters_dense=32,\n",
    "                      kernel_size1=1,\n",
    "                      kernel_size2=1,\n",
    "                      kernel_size3=1,\n",
    "                      kernel_size4=1,\n",
    "                      kernel_size5=1,\n",
    "                      kernel_size6=1,\n",
    "                      pool_size1=1,\n",
    "                      pool_size2=1,\n",
    "                      pool_size3=1,\n",
    "                      pool_size4=1,\n",
    "                      pool_size5=1,\n",
    "                      pool_size6=1,\n",
    "                      stride1=1,\n",
    "                      stride2=1,\n",
    "                      stride3=1,\n",
    "                      stride4=1,\n",
    "                      stride5=1,\n",
    "                      stride6=1,\n",
    "                      optimizer='RMSprop', \n",
    "                      layers=1,\n",
    "                      init='glorot_normal',\n",
    "                      lr=0.001, \n",
    "                      momentum=0.9,\n",
    "                      decay=0.9,\n",
    "                      beta_1=0.9,\n",
    "                      beta_2=0.999,\n",
    "                      rho=0.9,\n",
    "                      nesterov=False,\n",
    "                      activation = ELU(),\n",
    "                      dropout_rate = 0.0,\n",
    "                      epsilon=1e-08,\n",
    "                      schedule_decay=0.004):\n",
    "    \n",
    "    sequence_input = Input(shape=(sequence_length, dim))\n",
    "    if(layers == 1):\n",
    "        x = Conv1D(filters1, kernel_size1)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif(layers == 2):\n",
    "        x = Conv1D(filters1, kernel_size1, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters2, kernel_size2, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_2==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        elif(max_meanPool_2==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif(layers == 3):\n",
    "        x = Conv1D(filters1, kernel_size1, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters2, kernel_size2, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_2==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        elif(max_meanPool_2==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters3, kernel_size3, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_3==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        elif(max_meanPool_3==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif(layers == 4):\n",
    "        x = Conv1D(filters1, kernel_size1, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters2, kernel_size2, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_2==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        elif(max_meanPool_2==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters3, kernel_size3, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_3==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        elif(max_meanPool_3==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters4, kernel_size4, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_4==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        elif(max_meanPool_4==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif(layers == 5):\n",
    "        x = Conv1D(filters1, kernel_size1, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters2, kernel_size2, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_2==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        elif(max_meanPool_2==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters3, kernel_size3, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_3==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        elif(max_meanPool_3==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters4, kernel_size4, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_4==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        elif(max_meanPool_4==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters5, kernel_size5, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_5==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size5, stride=stride5)(x)\n",
    "        elif(max_meanPool_5==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size5, stride=stride5)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    else:\n",
    "        x = Conv1D(filters1, kernel_size1, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_1==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        elif(max_meanPool_1==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size1, stride=stride1)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters2, kernel_size2, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_2==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        elif(max_meanPool_2==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size2, stride=stride2)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters3, kernel_size3, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_3==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        elif(max_meanPool_3==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size3, stride=stride3)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters4, kernel_size4, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_4==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        elif(max_meanPool_4==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size4, stride=stride4)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters5, kernel_size5, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_5==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size5, stride=stride5)(x)\n",
    "        elif(max_meanPool_5==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size5, stride=stride5)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x = Conv1D(filters6, kernel_size6, init=init)(sequence_input)\n",
    "        x = activation(x)\n",
    "        if(max_meanPool_6==1):\n",
    "            x = MaxPooling1D(pool_size=pool_size6, stride=stride6)(x)\n",
    "        elif(max_meanPool_6==2):  \n",
    "            x = AveragePooling1D(pool_size=pool_size6, stride=stride6)(x)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(filters_dense, init=init)(x)\n",
    "    x = activation(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    preds = Dense(dense)(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "\n",
    "    if(optimizer == 'SGD'):\n",
    "        sgd = SGD(lr=lr, momentum=momentum, decay=decay, nesterov=nesterov)\n",
    "    elif(optimizer == 'RMSprop'):\n",
    "        sgd = RMSprop(lr=lr, rho=rho)\n",
    "    elif(optimizer == 'Nadam'):\n",
    "        sgd = Nadam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, schedule_decay=schedule_decay)\n",
    "    elif(optimizer == 'Adagrad'):\n",
    "        sgd = Adagrad(lr=lr, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adadelta'):\n",
    "        sgd = Adadelta(lr=lr, rho=rho, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adam'):\n",
    "        sgd = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay)\n",
    "    elif(optimizer == 'Adamax'):\n",
    "        sgd = Adamax(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting out 14 days, with a 30.0 day window. \n",
      "Feature space:  ['precip.cm', 'tair.C', 'rh.pct', 'wind_sp.m_per_s', 'irradiance.w_per_m.2', 'average_clay', 'average_sand', 'average_silt']\n",
      "Response:  ['imputed']\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Elapsed: 0.13 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    7.5s finished\n"
     ]
    }
   ],
   "source": [
    "print('Forecasting out {0} days, with a {1:0.1f} day window. '.format(horizon, (sequence_length)))\n",
    "print('Feature space: ', feat_cols)\n",
    "print('Response: ', resp_cols)\n",
    "\n",
    "model = KerasRegressor(build_fn=create_tCNN_model, shuffle=True, verbose=0)\n",
    "\n",
    "# init = ['uniform', 'normal', 'zero', 'glorot_uniform', 'glorot_normal', 'lecun_uniform', \n",
    "#                       'lecun_normal', 'he_normal', 'he_uniform']\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "layers = [3]\n",
    "nesterov = [False]\n",
    "\n",
    "filters1 = [64]\n",
    "filters2 = [32, 64, 128, 256, 512]\n",
    "filters3 = [32, 64, 128, 256, 512]\n",
    "filters4 = [32]\n",
    "filters5 = [32]\n",
    "filters6 = [32]\n",
    "filters_dense = [32, 64, 128, 256, 512]\n",
    "\n",
    "kernel_size1 = [3]\n",
    "kernel_size2 = [1,2,3,4]\n",
    "kernel_size3 = [1,2,3,4]\n",
    "kernel_size4 = [1]\n",
    "kernel_size5 = [1]\n",
    "kernel_size6 = [1]\n",
    "\n",
    "pool_size1 = [4] \n",
    "pool_size2 = [1,2,3,4] \n",
    "pool_size3 = [1,2,3,4] \n",
    "pool_size4 = [1] \n",
    "pool_size5 = [1] \n",
    "pool_size6 = [1]\n",
    "\n",
    "stride1 = [3]\n",
    "stride2 = [1,2,3,4]\n",
    "stride3 = [1,2,3,4]\n",
    "stride4 = [1]\n",
    "stride5 = [1]\n",
    "stride6 = [1]\n",
    "\n",
    "max_meanPool_1=[2]\n",
    "max_meanPool_2=[1,2]\n",
    "max_meanPool_3=[1,2]\n",
    "max_meanPool_4=[2]\n",
    "max_meanPool_5=[2]\n",
    "max_meanPool_6=[2]\n",
    "\n",
    "batch_size = [1,2,3,4,5,6]\n",
    "# batch_size = [64]\n",
    "epochs = [1]\n",
    "# lr = [10**k for k in range(-5, -1)]\n",
    "lr=[0.00015, 0.0001, 0.0005, 0.001]\n",
    "\n",
    "optimizer = ['RMSprop']\n",
    "init = ['lecun_normal']\n",
    "\n",
    "momentum=[0.9]\n",
    "dropout_rate=[0.0]\n",
    "# decay = np.arange(0,.1,0.001).tolist()\n",
    "decay = [0.012]\n",
    "# decay = np.arange(0.06,0.1,0.001).tolist()\n",
    "# beta_1 = np.random.uniform(low=0.90, high=1.0, size=20).tolist()\n",
    "# beta_2 = np.random.uniform(0.90, 1.0, 20).tolist()\n",
    "beta_1 = [0.9130588049258307]\n",
    "beta_2 = [0.9498343369399377]\n",
    "# rho = np.random.uniform(0.80, 0.95, 20).tolist()\n",
    "rho = [0.8026518983228177]\n",
    "# epsilon = [1e-09, 1e-08,1e-07, 1e-06, 1e-05, 1e-04]\n",
    "epsilon = [1e-09]\n",
    "# schedule_decay = np.arange(0.001,0.01,0.0005).tolist()\n",
    "schedule_decay=[0.0055]\n",
    "param_grid = dict(batch_size=batch_size, \n",
    "                  epsilon=epsilon,\n",
    "                  schedule_decay=schedule_decay,\n",
    "                  epochs=epochs, \n",
    "                  layers=layers, \n",
    "                  filters1=filters1,\n",
    "                  filters2=filters2,\n",
    "                  filters3=filters3,\n",
    "                  filters4=filters4,\n",
    "                  filters5=filters5,\n",
    "                  filters6=filters6,\n",
    "                  filters_dense=filters_dense,\n",
    "                  stride1=stride1,\n",
    "                  stride2=stride2,\n",
    "                  stride3=stride3,\n",
    "                  stride4=stride4,\n",
    "                  stride5=stride5,\n",
    "                  stride6=stride6,\n",
    "                  pool_size1=pool_size1,\n",
    "                  pool_size2=pool_size2,\n",
    "                  pool_size3=pool_size3,\n",
    "                  pool_size4=pool_size4,\n",
    "                  pool_size5=pool_size5,\n",
    "                  pool_size6=pool_size6,\n",
    "                  kernel_size1=kernel_size1,\n",
    "                  kernel_size2=kernel_size2,\n",
    "                  kernel_size3=kernel_size3,\n",
    "                  kernel_size4=kernel_size4,\n",
    "                  kernel_size5=kernel_size5,\n",
    "                  kernel_size6=kernel_size6,\n",
    "                  optimizer=optimizer,\n",
    "                  lr=lr,\n",
    "                  decay=decay,\n",
    "                  init=init,\n",
    "                  beta_1=beta_1,\n",
    "                  beta_2=beta_2,\n",
    "                  nesterov=nesterov,\n",
    "                  rho=rho,\n",
    "                  momentum=momentum,\n",
    "                  dropout_rate=dropout_rate,\n",
    "                  max_meanPool_1=max_meanPool_1, \n",
    "                  max_meanPool_2=max_meanPool_2, \n",
    "                  max_meanPool_3=max_meanPool_3, \n",
    "                  max_meanPool_4=max_meanPool_4, \n",
    "                  max_meanPool_5=max_meanPool_5,\n",
    "                  max_meanPool_6=max_meanPool_6)\n",
    "\n",
    "start_timing()\n",
    "sweeper = random_sweep(\n",
    "    train_X, train_y, \n",
    "    model, param_grid,\n",
    "    scoring=compute_mae, \n",
    "    n_iter=1, n_jobs=3, \n",
    "    refit=False, cv=3, verbose=1)\n",
    "report_timing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Std</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>decay</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>filters1</th>\n",
       "      <th>...</th>\n",
       "      <th>pool_size5</th>\n",
       "      <th>pool_size6</th>\n",
       "      <th>rho</th>\n",
       "      <th>schedule_decay</th>\n",
       "      <th>stride1</th>\n",
       "      <th>stride2</th>\n",
       "      <th>stride3</th>\n",
       "      <th>stride4</th>\n",
       "      <th>stride5</th>\n",
       "      <th>stride6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.594888</td>\n",
       "      <td>2.191362</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score       Std  batch_size    beta_1    beta_2  decay  dropout_rate  \\\n",
       "0  1.594888  2.191362           6  0.913059  0.949834  0.012           0.0   \n",
       "\n",
       "   epochs       epsilon  filters1   ...     pool_size5  pool_size6       rho  \\\n",
       "0       1  1.000000e-09        64   ...              1           1  0.802652   \n",
       "\n",
       "   schedule_decay  stride1  stride2 stride3  stride4  stride5  stride6  \n",
       "0          0.0055        3        4       3        1        1        1  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sweep_stats(sweeper)\n",
    "# FILE_PATH = os.path.join(CWD, \"../data/results_data/best_params/tCNN_W30_H14_Resp-soilM_Feat-soilType-allWeather_fineTune_run2.csv\")\n",
    "# results.to_csv(FILE_PATH)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 6,\n",
       " 'beta_1': 0.9130588049258307,\n",
       " 'beta_2': 0.9498343369399377,\n",
       " 'decay': 0.012,\n",
       " 'dropout_rate': 0.0,\n",
       " 'epochs': 1,\n",
       " 'epsilon': 1e-09,\n",
       " 'filters1': 64,\n",
       " 'filters2': 512,\n",
       " 'filters3': 256,\n",
       " 'filters4': 32,\n",
       " 'filters5': 32,\n",
       " 'filters6': 32,\n",
       " 'filters_dense': 256,\n",
       " 'init': 'lecun_normal',\n",
       " 'kernel_size1': 3,\n",
       " 'kernel_size2': 4,\n",
       " 'kernel_size3': 1,\n",
       " 'kernel_size4': 1,\n",
       " 'kernel_size5': 1,\n",
       " 'kernel_size6': 1,\n",
       " 'layers': 3,\n",
       " 'lr': 0.001,\n",
       " 'max_meanPool_1': 2,\n",
       " 'max_meanPool_2': 1,\n",
       " 'max_meanPool_3': 1,\n",
       " 'max_meanPool_4': 2,\n",
       " 'max_meanPool_5': 2,\n",
       " 'max_meanPool_6': 2,\n",
       " 'momentum': 0.9,\n",
       " 'nesterov': False,\n",
       " 'optimizer': 'RMSprop',\n",
       " 'pool_size1': 4,\n",
       " 'pool_size2': 4,\n",
       " 'pool_size3': 1,\n",
       " 'pool_size4': 1,\n",
       " 'pool_size5': 1,\n",
       " 'pool_size6': 1,\n",
       " 'rho': 0.8026518983228177,\n",
       " 'schedule_decay': 0.0055,\n",
       " 'stride1': 3,\n",
       " 'stride2': 4,\n",
       " 'stride3': 3,\n",
       " 'stride4': 1,\n",
       " 'stride5': 1,\n",
       " 'stride6': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5244/5244 [==============================] - 4s 714us/step - loss: 1.0637 - mean_squared_error: 4.2698\n",
      "Epoch 2/5\n",
      "5244/5244 [==============================] - 3s 653us/step - loss: 0.5078 - mean_squared_error: 0.4609\n",
      "Epoch 3/5\n",
      "5244/5244 [==============================] - 3s 642us/step - loss: 0.4827 - mean_squared_error: 0.4190\n",
      "Epoch 4/5\n",
      "5244/5244 [==============================] - 3s 642us/step - loss: 0.4680 - mean_squared_error: 0.3974\n",
      "Epoch 5/5\n",
      "5244/5244 [==============================] - 3s 644us/step - loss: 0.4467 - mean_squared_error: 0.3574\n",
      "5244/5244 [==============================] - 1s 152us/step\n",
      "1364/1364 [==============================] - 0s 154us/step\n",
      "5244/5244 [==============================] - 1s 150us/step\n",
      "1364/1364 [==============================] - 0s 157us/step\n",
      "5244/5244 [==============================] - 1s 159us/step\n",
      "1364/1364 [==============================] - 0s 159us/step\n",
      "5244/5244 [==============================] - 1s 154us/step\n",
      "1364/1364 [==============================] - 0s 167us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.029693 ± 0.000000', 'Testing MAE 0.048434 ± 0.000000')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    RUN = i+1\n",
    "    print('Best Run Num: {0}'.format(RUN))\n",
    "    params = results.iloc[-RUN,2:].to_dict()\n",
    "    params\n",
    "    params['kernel_size1'] = int(params['kernel_size1'])\n",
    "    params['kernel_size2'] = int(params['kernel_size2'])\n",
    "    params['kernel_size3'] = int(params['kernel_size3'])\n",
    "    params['kernel_size4'] = int(params['kernel_size4'])\n",
    "    params['kernel_size5'] = int(params['kernel_size5'])\n",
    "    params['kernel_size6'] = int(params['kernel_size6'])\n",
    "\n",
    "    params['pool_size1'] = int(params['pool_size1'])\n",
    "    params['pool_size2'] = int(params['pool_size2'])\n",
    "    params['pool_size3'] = int(params['pool_size3'])\n",
    "    params['pool_size4'] = int(params['pool_size4'])\n",
    "    params['pool_size5'] = int(params['pool_size5'])\n",
    "    params['pool_size6'] = int(params['pool_size6'])\n",
    "\n",
    "    params['stride1'] = int(params['stride1'])\n",
    "    params['stride2'] = int(params['stride2'])\n",
    "    params['stride3'] = int(params['stride3'])\n",
    "    params['stride4'] = int(params['stride4'])\n",
    "    params['stride5'] = int(params['stride5'])\n",
    "    params['stride6'] = int(params['stride6'])\n",
    "\n",
    "    params['dropout_rate'] = params.pop('dropout_rate')\n",
    "    ### Testing the best params\n",
    "\n",
    "    np.random.seed(84)\n",
    "    tf.set_random_seed(84)\n",
    "\n",
    "    params['epochs'] = 5\n",
    "\n",
    "    train_results, test_results = [], []\n",
    "    ITERATIONS=1\n",
    "    VERBOSE=1\n",
    "\n",
    "    # params\n",
    "\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "#     reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-08, mode='auto', verbose=1)\n",
    "\n",
    "    for i in range(ITERATIONS):\n",
    "        model = KerasRegressor(build_fn=create_tCNN_model, shuffle=True, verbose=VERBOSE, **params)\n",
    "    #     history = model.fit(train_X, train_y, verbose=VERBOSE, validation_split = 0.15, callbacks=[early_stopping])\n",
    "        history = model.fit(train_X, train_y, verbose=VERBOSE, validation_split = None)\n",
    "        train_results.append(test_mae(model)[0])\n",
    "        test_results.append(test_mae(model)[1])\n",
    "    report(train_results, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Num: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 3,\n",
       " 'beta_1': 0.9130588049258307,\n",
       " 'beta_2': 0.9498343369399377,\n",
       " 'decay': 0.012,\n",
       " 'dropout_rate': 0.0,\n",
       " 'epochs': 40,\n",
       " 'epsilon': 1e-09,\n",
       " 'filters1': 64,\n",
       " 'filters2': 128,\n",
       " 'filters3': 256,\n",
       " 'filters4': 32,\n",
       " 'filters5': 32,\n",
       " 'filters6': 32,\n",
       " 'filters_dense': 256,\n",
       " 'init': 'lecun_normal',\n",
       " 'kernel_size1': 3,\n",
       " 'kernel_size2': 4,\n",
       " 'kernel_size3': 4,\n",
       " 'kernel_size4': 1,\n",
       " 'kernel_size5': 1,\n",
       " 'kernel_size6': 1,\n",
       " 'layers': 3,\n",
       " 'lr': 0.001,\n",
       " 'max_meanPool_1': 2,\n",
       " 'max_meanPool_2': 2,\n",
       " 'max_meanPool_3': 1,\n",
       " 'max_meanPool_4': 2,\n",
       " 'max_meanPool_5': 2,\n",
       " 'max_meanPool_6': 2,\n",
       " 'momentum': 0.9,\n",
       " 'nesterov': False,\n",
       " 'optimizer': 'RMSprop',\n",
       " 'pool_size1': 4,\n",
       " 'pool_size2': 1,\n",
       " 'pool_size3': 3,\n",
       " 'pool_size4': 1,\n",
       " 'pool_size5': 1,\n",
       " 'pool_size6': 1,\n",
       " 'rho': 0.8026518983228177,\n",
       " 'schedule_decay': 0.0055,\n",
       " 'stride1': 3,\n",
       " 'stride2': 2,\n",
       " 'stride3': 1,\n",
       " 'stride4': 1,\n",
       " 'stride5': 1,\n",
       " 'stride6': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 787 samples\n",
      "Epoch 1/150\n",
      "4457/4457 [==============================] - 23s 5ms/step - loss: 0.6623 - mean_squared_error: 4.1181 - val_loss: 1.6089 - val_mean_squared_error: 3.2941\n",
      "Epoch 2/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.4821 - mean_squared_error: 0.3904 - val_loss: 0.6475 - val_mean_squared_error: 0.6752\n",
      "Epoch 3/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.4494 - mean_squared_error: 0.3488 - val_loss: 0.8719 - val_mean_squared_error: 1.2019\n",
      "Epoch 4/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.4366 - mean_squared_error: 0.3228 - val_loss: 1.0578 - val_mean_squared_error: 1.5612\n",
      "Epoch 5/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.4128 - mean_squared_error: 0.2825 - val_loss: 0.8305 - val_mean_squared_error: 1.1066\n",
      "Epoch 6/150\n",
      "4457/4457 [==============================] - 20s 5ms/step - loss: 0.4025 - mean_squared_error: 0.2651 - val_loss: 1.2725 - val_mean_squared_error: 2.2649\n",
      "Epoch 7/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3955 - mean_squared_error: 0.2581 - val_loss: 0.6117 - val_mean_squared_error: 0.6626\n",
      "Epoch 8/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3801 - mean_squared_error: 0.2358 - val_loss: 0.7200 - val_mean_squared_error: 0.8359\n",
      "Epoch 9/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3737 - mean_squared_error: 0.2307 - val_loss: 0.7638 - val_mean_squared_error: 1.0264\n",
      "Epoch 10/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3673 - mean_squared_error: 0.2184 - val_loss: 0.5868 - val_mean_squared_error: 0.6695\n",
      "Epoch 11/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.3598 - mean_squared_error: 0.2058 - val_loss: 0.6536 - val_mean_squared_error: 0.7545\n",
      "Epoch 12/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.3529 - mean_squared_error: 0.2038 - val_loss: 0.6517 - val_mean_squared_error: 0.7776\n",
      "Epoch 13/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3450 - mean_squared_error: 0.1958 - val_loss: 0.6220 - val_mean_squared_error: 0.6407\n",
      "Epoch 14/150\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.3435 - mean_squared_error: 0.1904 - val_loss: 0.6653 - val_mean_squared_error: 0.6979\n",
      "Epoch 15/150\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.3355 - mean_squared_error: 0.1821 - val_loss: 1.0001 - val_mean_squared_error: 1.4571\n",
      "Epoch 16/150\n",
      "4457/4457 [==============================] - 20s 5ms/step - loss: 0.3304 - mean_squared_error: 0.1764 - val_loss: 0.9165 - val_mean_squared_error: 1.2186\n",
      "Epoch 17/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.3293 - mean_squared_error: 0.1790 - val_loss: 1.1268 - val_mean_squared_error: 1.5938\n",
      "Epoch 18/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.3298 - mean_squared_error: 0.1753 - val_loss: 0.5265 - val_mean_squared_error: 0.5572\n",
      "Epoch 19/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.3234 - mean_squared_error: 0.1696 - val_loss: 0.7907 - val_mean_squared_error: 0.9823\n",
      "Epoch 20/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3240 - mean_squared_error: 0.1694 - val_loss: 0.9728 - val_mean_squared_error: 1.2543\n",
      "Epoch 21/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.3209 - mean_squared_error: 0.1656 - val_loss: 0.6349 - val_mean_squared_error: 0.7271\n",
      "Epoch 22/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.3175 - mean_squared_error: 0.1631 - val_loss: 0.9971 - val_mean_squared_error: 1.5410\n",
      "Epoch 23/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.3101 - mean_squared_error: 0.1564 - val_loss: 0.7230 - val_mean_squared_error: 0.8699\n",
      "Epoch 24/150\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.3129 - mean_squared_error: 0.1573 - val_loss: 0.7185 - val_mean_squared_error: 0.8266\n",
      "Epoch 25/150\n",
      "4457/4457 [==============================] - 23s 5ms/step - loss: 0.3067 - mean_squared_error: 0.1510 - val_loss: 1.1493 - val_mean_squared_error: 1.7193\n",
      "Epoch 26/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.2994 - mean_squared_error: 0.1451 - val_loss: 0.6676 - val_mean_squared_error: 0.7926\n",
      "Epoch 27/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.3011 - mean_squared_error: 0.1470 - val_loss: 0.5792 - val_mean_squared_error: 0.6044\n",
      "Epoch 28/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.3030 - mean_squared_error: 0.1489 - val_loss: 1.1868 - val_mean_squared_error: 1.7796\n",
      "Epoch 29/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.3022 - mean_squared_error: 0.1475 - val_loss: 0.7095 - val_mean_squared_error: 0.8150\n",
      "Epoch 30/150\n",
      "4457/4457 [==============================] - 20s 5ms/step - loss: 0.2993 - mean_squared_error: 0.1437 - val_loss: 0.6800 - val_mean_squared_error: 0.7786\n",
      "Epoch 31/150\n",
      "4457/4457 [==============================] - 23s 5ms/step - loss: 0.3019 - mean_squared_error: 0.1468 - val_loss: 0.7086 - val_mean_squared_error: 0.7956\n",
      "Epoch 32/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.2942 - mean_squared_error: 0.1400 - val_loss: 0.7039 - val_mean_squared_error: 0.8917\n",
      "Epoch 33/150\n",
      "4457/4457 [==============================] - 20s 5ms/step - loss: 0.2901 - mean_squared_error: 0.1346 - val_loss: 0.9613 - val_mean_squared_error: 1.3040\n",
      "Epoch 34/150\n",
      "4446/4457 [============================>.] - ETA: 0s - loss: 0.2945 - mean_squared_error: 0.1405\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.2944 - mean_squared_error: 0.1404 - val_loss: 0.7601 - val_mean_squared_error: 0.8630\n",
      "Epoch 35/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.1641 - mean_squared_error: 0.0453 - val_loss: 0.6927 - val_mean_squared_error: 0.8039\n",
      "Epoch 36/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.1411 - mean_squared_error: 0.0341 - val_loss: 0.6959 - val_mean_squared_error: 0.7982\n",
      "Epoch 37/150\n",
      "4457/4457 [==============================] - 20s 5ms/step - loss: 0.1321 - mean_squared_error: 0.0302 - val_loss: 0.7875 - val_mean_squared_error: 0.9567\n",
      "Epoch 38/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.1249 - mean_squared_error: 0.0274 - val_loss: 0.7273 - val_mean_squared_error: 0.8854\n",
      "Epoch 39/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.1188 - mean_squared_error: 0.0244 - val_loss: 0.6948 - val_mean_squared_error: 0.8304\n",
      "Epoch 40/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.1152 - mean_squared_error: 0.0231 - val_loss: 0.7631 - val_mean_squared_error: 0.9275\n",
      "Epoch 41/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.1092 - mean_squared_error: 0.0207 - val_loss: 0.7849 - val_mean_squared_error: 0.9590\n",
      "Epoch 42/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.1045 - mean_squared_error: 0.0192 - val_loss: 0.7534 - val_mean_squared_error: 0.8839\n",
      "Epoch 43/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.1025 - mean_squared_error: 0.0181 - val_loss: 0.7390 - val_mean_squared_error: 0.9017\n",
      "Epoch 44/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0998 - mean_squared_error: 0.0171 - val_loss: 0.7799 - val_mean_squared_error: 0.9566\n",
      "Epoch 45/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0956 - mean_squared_error: 0.0159 - val_loss: 0.8024 - val_mean_squared_error: 1.0012\n",
      "Epoch 46/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0932 - mean_squared_error: 0.0150 - val_loss: 0.7557 - val_mean_squared_error: 0.9073\n",
      "Epoch 47/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0907 - mean_squared_error: 0.0141 - val_loss: 0.6813 - val_mean_squared_error: 0.8071\n",
      "Epoch 48/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0893 - mean_squared_error: 0.0135 - val_loss: 0.7488 - val_mean_squared_error: 0.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "4443/4457 [============================>.] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.0132\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0878 - mean_squared_error: 0.0132 - val_loss: 0.7372 - val_mean_squared_error: 0.8883\n",
      "Epoch 50/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0574 - mean_squared_error: 0.0063 - val_loss: 0.7647 - val_mean_squared_error: 0.9306\n",
      "Epoch 51/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0530 - mean_squared_error: 0.0056 - val_loss: 0.7404 - val_mean_squared_error: 0.8916\n",
      "Epoch 52/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0506 - mean_squared_error: 0.0052 - val_loss: 0.7213 - val_mean_squared_error: 0.8574\n",
      "Epoch 53/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0491 - mean_squared_error: 0.0050 - val_loss: 0.7472 - val_mean_squared_error: 0.9024\n",
      "Epoch 54/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0476 - mean_squared_error: 0.0048 - val_loss: 0.7565 - val_mean_squared_error: 0.9231\n",
      "Epoch 55/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0461 - mean_squared_error: 0.0046 - val_loss: 0.7413 - val_mean_squared_error: 0.8935\n",
      "Epoch 56/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0459 - mean_squared_error: 0.0046 - val_loss: 0.7250 - val_mean_squared_error: 0.8644\n",
      "Epoch 57/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0444 - mean_squared_error: 0.0044 - val_loss: 0.7518 - val_mean_squared_error: 0.9063\n",
      "Epoch 58/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0434 - mean_squared_error: 0.0041 - val_loss: 0.7317 - val_mean_squared_error: 0.8769\n",
      "Epoch 59/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0423 - mean_squared_error: 0.0041 - val_loss: 0.7440 - val_mean_squared_error: 0.8936\n",
      "Epoch 60/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0415 - mean_squared_error: 0.0040 - val_loss: 0.7570 - val_mean_squared_error: 0.9154\n",
      "Epoch 61/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0411 - mean_squared_error: 0.0038 - val_loss: 0.7594 - val_mean_squared_error: 0.9218\n",
      "Epoch 62/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0404 - mean_squared_error: 0.0037 - val_loss: 0.7492 - val_mean_squared_error: 0.9061\n",
      "Epoch 63/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0398 - mean_squared_error: 0.0036 - val_loss: 0.7340 - val_mean_squared_error: 0.8789\n",
      "Epoch 64/150\n",
      "4455/4457 [============================>.] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0035\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0388 - mean_squared_error: 0.0035 - val_loss: 0.7547 - val_mean_squared_error: 0.9144\n",
      "Epoch 65/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0331 - mean_squared_error: 0.0030 - val_loss: 0.7429 - val_mean_squared_error: 0.8931\n",
      "Epoch 66/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0320 - mean_squared_error: 0.0029 - val_loss: 0.7440 - val_mean_squared_error: 0.8951\n",
      "Epoch 67/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0316 - mean_squared_error: 0.0029 - val_loss: 0.7469 - val_mean_squared_error: 0.9025\n",
      "Epoch 68/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0311 - mean_squared_error: 0.0029 - val_loss: 0.7469 - val_mean_squared_error: 0.8990\n",
      "Epoch 69/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0309 - mean_squared_error: 0.0028 - val_loss: 0.7461 - val_mean_squared_error: 0.8995\n",
      "Epoch 70/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0307 - mean_squared_error: 0.0028 - val_loss: 0.7463 - val_mean_squared_error: 0.9010\n",
      "Epoch 71/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0304 - mean_squared_error: 0.0028 - val_loss: 0.7491 - val_mean_squared_error: 0.9037\n",
      "Epoch 72/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0304 - mean_squared_error: 0.0028 - val_loss: 0.7491 - val_mean_squared_error: 0.9052\n",
      "Epoch 73/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0300 - mean_squared_error: 0.0028 - val_loss: 0.7465 - val_mean_squared_error: 0.8999\n",
      "Epoch 74/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0298 - mean_squared_error: 0.0027 - val_loss: 0.7491 - val_mean_squared_error: 0.9039\n",
      "Epoch 75/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0296 - mean_squared_error: 0.0027 - val_loss: 0.7500 - val_mean_squared_error: 0.9053\n",
      "Epoch 76/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0293 - mean_squared_error: 0.0027 - val_loss: 0.7460 - val_mean_squared_error: 0.8994\n",
      "Epoch 77/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0292 - mean_squared_error: 0.0027 - val_loss: 0.7423 - val_mean_squared_error: 0.8921\n",
      "Epoch 78/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0290 - mean_squared_error: 0.0027 - val_loss: 0.7477 - val_mean_squared_error: 0.9010\n",
      "Epoch 79/150\n",
      "4452/4457 [============================>.] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0027\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0288 - mean_squared_error: 0.0027 - val_loss: 0.7455 - val_mean_squared_error: 0.8978\n",
      "Epoch 80/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0276 - mean_squared_error: 0.0026 - val_loss: 0.7463 - val_mean_squared_error: 0.8991\n",
      "Epoch 81/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0274 - mean_squared_error: 0.0026 - val_loss: 0.7440 - val_mean_squared_error: 0.8952\n",
      "Epoch 82/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0273 - mean_squared_error: 0.0026 - val_loss: 0.7455 - val_mean_squared_error: 0.8976\n",
      "Epoch 83/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0272 - mean_squared_error: 0.0026 - val_loss: 0.7454 - val_mean_squared_error: 0.8972\n",
      "Epoch 84/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0272 - mean_squared_error: 0.0026 - val_loss: 0.7451 - val_mean_squared_error: 0.8969\n",
      "Epoch 85/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0271 - mean_squared_error: 0.0026 - val_loss: 0.7463 - val_mean_squared_error: 0.8988\n",
      "Epoch 86/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0271 - mean_squared_error: 0.0026 - val_loss: 0.7463 - val_mean_squared_error: 0.8988\n",
      "Epoch 87/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0270 - mean_squared_error: 0.0026 - val_loss: 0.7453 - val_mean_squared_error: 0.8970\n",
      "Epoch 88/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0270 - mean_squared_error: 0.0026 - val_loss: 0.7466 - val_mean_squared_error: 0.8991\n",
      "Epoch 89/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0269 - mean_squared_error: 0.0026 - val_loss: 0.7462 - val_mean_squared_error: 0.8986\n",
      "Epoch 90/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0269 - mean_squared_error: 0.0025 - val_loss: 0.7463 - val_mean_squared_error: 0.8986\n",
      "Epoch 91/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0268 - mean_squared_error: 0.0025 - val_loss: 0.7466 - val_mean_squared_error: 0.8991\n",
      "Epoch 92/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0268 - mean_squared_error: 0.0025 - val_loss: 0.7464 - val_mean_squared_error: 0.8990\n",
      "Epoch 93/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0267 - mean_squared_error: 0.0025 - val_loss: 0.7465 - val_mean_squared_error: 0.8991\n",
      "Epoch 94/150\n",
      "4443/4457 [============================>.] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0025\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0266 - mean_squared_error: 0.0025 - val_loss: 0.7464 - val_mean_squared_error: 0.8991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0264 - mean_squared_error: 0.0025 - val_loss: 0.7463 - val_mean_squared_error: 0.8986\n",
      "Epoch 96/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0264 - mean_squared_error: 0.0025 - val_loss: 0.7455 - val_mean_squared_error: 0.8975\n",
      "Epoch 97/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7456 - val_mean_squared_error: 0.8975\n",
      "Epoch 98/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7463 - val_mean_squared_error: 0.8987\n",
      "Epoch 99/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8985\n",
      "Epoch 100/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7464 - val_mean_squared_error: 0.8990\n",
      "Epoch 101/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7458 - val_mean_squared_error: 0.8980\n",
      "Epoch 102/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7459 - val_mean_squared_error: 0.8981\n",
      "Epoch 103/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8982\n",
      "Epoch 104/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8983\n",
      "Epoch 105/150\n",
      "4457/4457 [==============================] - 21s 5ms/step - loss: 0.0263 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 106/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 107/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0025 - val_loss: 0.7459 - val_mean_squared_error: 0.8981\n",
      "Epoch 108/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 109/150\n",
      "4446/4457 [============================>.] - ETA: 0s - loss: 0.0263 - mean_squared_error: 0.0025\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8982\n",
      "Epoch 110/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8985\n",
      "Epoch 111/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8985\n",
      "Epoch 112/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8985\n",
      "Epoch 113/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 114/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 115/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 116/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8982\n",
      "Epoch 117/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8983\n",
      "Epoch 118/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8986\n",
      "Epoch 119/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 120/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8985\n",
      "Epoch 121/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8982\n",
      "Epoch 122/150\n",
      "4457/4457 [==============================] - 20s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 123/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7462 - val_mean_squared_error: 0.8986\n",
      "Epoch 124/150\n",
      "4443/4457 [============================>.] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0025\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7460 - val_mean_squared_error: 0.8983\n",
      "Epoch 125/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 126/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 127/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 128/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 129/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 130/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 131/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 132/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 133/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 134/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 135/150\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 136/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 137/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8985\n",
      "Epoch 138/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 139/150\n",
      "4449/4457 [============================>.] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0025\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 140/150\n",
      "4457/4457 [==============================] - 18s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 142/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 143/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 144/150\n",
      "4457/4457 [==============================] - 22s 5ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 145/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 146/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 147/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "Epoch 148/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 149/150\n",
      "4457/4457 [==============================] - 17s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8984\n",
      "Epoch 150/150\n",
      "4457/4457 [==============================] - 19s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0025 - val_loss: 0.7461 - val_mean_squared_error: 0.8983\n",
      "5244/5244 [==============================] - 4s 765us/step\n",
      "1364/1364 [==============================] - 1s 780us/step\n",
      "5244/5244 [==============================] - 4s 841us/step\n",
      "1364/1364 [==============================] - 1s 826us/step\n",
      "5244/5244 [==============================] - 4s 801us/step\n",
      "1364/1364 [==============================] - 1s 798us/step\n",
      "5244/5244 [==============================] - 4s 786us/step\n",
      "1364/1364 [==============================] - 1s 792us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Training MAE 0.009258 ± 0.000000', 'Testing MAE 0.048564 ± 0.000000')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN = 6\n",
    "\n",
    "print('Best Run Num: {0}'.format(RUN))\n",
    "params = results.iloc[-RUN,2:].to_dict()\n",
    "params\n",
    "params['kernel_size1'] = int(params['kernel_size1'])\n",
    "params['kernel_size2'] = int(params['kernel_size2'])\n",
    "params['kernel_size3'] = int(params['kernel_size3'])\n",
    "params['kernel_size4'] = int(params['kernel_size4'])\n",
    "params['kernel_size5'] = int(params['kernel_size5'])\n",
    "params['kernel_size6'] = int(params['kernel_size6'])\n",
    "\n",
    "params['pool_size1'] = int(params['pool_size1'])\n",
    "params['pool_size2'] = int(params['pool_size2'])\n",
    "params['pool_size3'] = int(params['pool_size3'])\n",
    "params['pool_size4'] = int(params['pool_size4'])\n",
    "params['pool_size5'] = int(params['pool_size5'])\n",
    "params['pool_size6'] = int(params['pool_size6'])\n",
    "\n",
    "params['stride1'] = int(params['stride1'])\n",
    "params['stride2'] = int(params['stride2'])\n",
    "params['stride3'] = int(params['stride3'])\n",
    "params['stride4'] = int(params['stride4'])\n",
    "params['stride5'] = int(params['stride5'])\n",
    "params['stride6'] = int(params['stride6'])\n",
    "\n",
    "params['dropout_rate'] = params.pop('dropout_rate')\n",
    "### Testing the best params\n",
    "\n",
    "np.random.seed(84)\n",
    "tf.set_random_seed(84)\n",
    "\n",
    "params['epochs'] = 150\n",
    "\n",
    "train_results, test_results = [], []\n",
    "ITERATIONS=1\n",
    "VERBOSE=1\n",
    "\n",
    "# params\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=15, min_lr=1e-08, mode='auto', verbose=1)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    model = KerasRegressor(build_fn=create_tCNN_model, shuffle=True, verbose=VERBOSE, **params)\n",
    "    history = model.fit(train_X, train_y, verbose=VERBOSE, validation_split = 0.15, callbacks=[reduce_lr])\n",
    "#     history = model.fit(train_X, train_y, verbose=VERBOSE, validation_split = None)\n",
    "    train_results.append(test_mae(model)[0])\n",
    "    test_results.append(test_mae(model)[1])\n",
    "report(train_results, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.model.save('../data/results_data/models/CNN_dailyALLDATA_W30_H14_FULLMODEL.h5')\n",
    "model.model.save_weights('../data/results_data/models/CNN_dailyALLDATA_W30_H14_WEIGHTS_ONLY.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Std</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>decay</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>filters1</th>\n",
       "      <th>...</th>\n",
       "      <th>pool_size5</th>\n",
       "      <th>pool_size6</th>\n",
       "      <th>rho</th>\n",
       "      <th>schedule_decay</th>\n",
       "      <th>stride1</th>\n",
       "      <th>stride2</th>\n",
       "      <th>stride3</th>\n",
       "      <th>stride4</th>\n",
       "      <th>stride5</th>\n",
       "      <th>stride6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.884001</td>\n",
       "      <td>7.216298</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.824623</td>\n",
       "      <td>7.865014</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.507169</td>\n",
       "      <td>2.063936</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.473696</td>\n",
       "      <td>2.027749</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.335490</td>\n",
       "      <td>1.819293</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.225948</td>\n",
       "      <td>1.662097</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.181798</td>\n",
       "      <td>1.610822</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.068585</td>\n",
       "      <td>1.455542</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.004185</td>\n",
       "      <td>1.191110</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.961936</td>\n",
       "      <td>1.283685</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.674423</td>\n",
       "      <td>0.862755</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.599924</td>\n",
       "      <td>0.792121</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.585356</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.454159</td>\n",
       "      <td>0.588784</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.369758</td>\n",
       "      <td>0.456284</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.329660</td>\n",
       "      <td>0.414115</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.261457</td>\n",
       "      <td>0.305106</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.241776</td>\n",
       "      <td>0.285055</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.198008</td>\n",
       "      <td>0.222352</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.189231</td>\n",
       "      <td>0.212751</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.175418</td>\n",
       "      <td>0.178145</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.173917</td>\n",
       "      <td>0.180687</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.152976</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.130815</td>\n",
       "      <td>0.133770</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.108893</td>\n",
       "      <td>0.100045</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.098232</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.079292</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.092332</td>\n",
       "      <td>0.077202</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.085648</td>\n",
       "      <td>0.065881</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.075234</td>\n",
       "      <td>0.053359</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.055260</td>\n",
       "      <td>0.024166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.053632</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.049828</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.048948</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.037437</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.949834</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802652</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score       Std  batch_size    beta_1    beta_2  decay  dropout_rate  \\\n",
       "0   15.884001  7.216298           3  0.913059  0.949834  0.012           0.0   \n",
       "1    7.824623  7.865014           4  0.913059  0.949834  0.012           0.0   \n",
       "2    1.507169  2.063936           5  0.913059  0.949834  0.012           0.0   \n",
       "3    1.473696  2.027749           3  0.913059  0.949834  0.012           0.0   \n",
       "4    1.335490  1.819293           1  0.913059  0.949834  0.012           0.0   \n",
       "5    1.225948  1.662097           3  0.913059  0.949834  0.012           0.0   \n",
       "6    1.181798  1.610822           1  0.913059  0.949834  0.012           0.0   \n",
       "7    1.068585  1.455542           6  0.913059  0.949834  0.012           0.0   \n",
       "8    1.004185  1.191110           6  0.913059  0.949834  0.012           0.0   \n",
       "9    0.961936  1.283685           6  0.913059  0.949834  0.012           0.0   \n",
       "10   0.674423  0.862755           4  0.913059  0.949834  0.012           0.0   \n",
       "11   0.599924  0.792121           4  0.913059  0.949834  0.012           0.0   \n",
       "12   0.585356  0.765300           6  0.913059  0.949834  0.012           0.0   \n",
       "13   0.454159  0.588784           2  0.913059  0.949834  0.012           0.0   \n",
       "14   0.369758  0.456284           4  0.913059  0.949834  0.012           0.0   \n",
       "15   0.329660  0.414115           2  0.913059  0.949834  0.012           0.0   \n",
       "16   0.261457  0.305106           2  0.913059  0.949834  0.012           0.0   \n",
       "17   0.241776  0.285055           4  0.913059  0.949834  0.012           0.0   \n",
       "18   0.198008  0.222352           5  0.913059  0.949834  0.012           0.0   \n",
       "19   0.189231  0.212751           4  0.913059  0.949834  0.012           0.0   \n",
       "20   0.175418  0.178145           2  0.913059  0.949834  0.012           0.0   \n",
       "21   0.173917  0.180687           3  0.913059  0.949834  0.012           0.0   \n",
       "22   0.152976  0.152915           2  0.913059  0.949834  0.012           0.0   \n",
       "23   0.130815  0.133770           6  0.913059  0.949834  0.012           0.0   \n",
       "24   0.108893  0.100045           6  0.913059  0.949834  0.012           0.0   \n",
       "25   0.108187  0.098232           5  0.913059  0.949834  0.012           0.0   \n",
       "26   0.096897  0.079292           2  0.913059  0.949834  0.012           0.0   \n",
       "27   0.092332  0.077202           2  0.913059  0.949834  0.012           0.0   \n",
       "28   0.085648  0.065881           6  0.913059  0.949834  0.012           0.0   \n",
       "29   0.075234  0.053359           3  0.913059  0.949834  0.012           0.0   \n",
       "30   0.055260  0.024166           1  0.913059  0.949834  0.012           0.0   \n",
       "31   0.053632  0.018395           2  0.913059  0.949834  0.012           0.0   \n",
       "32   0.049828  0.007984           4  0.913059  0.949834  0.012           0.0   \n",
       "33   0.048948  0.017002           4  0.913059  0.949834  0.012           0.0   \n",
       "34   0.037437  0.003426           2  0.913059  0.949834  0.012           0.0   \n",
       "\n",
       "    epochs       epsilon  filters1   ...     pool_size5  pool_size6       rho  \\\n",
       "0       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "1       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "2       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "3       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "4       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "5       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "6       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "7       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "8       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "9       40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "10      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "11      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "12      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "13      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "14      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "15      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "16      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "17      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "18      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "19      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "20      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "21      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "22      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "23      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "24      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "25      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "26      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "27      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "28      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "29      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "30      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "31      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "32      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "33      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "34      40  1.000000e-09        64   ...              1           1  0.802652   \n",
       "\n",
       "    schedule_decay  stride1  stride2 stride3  stride4  stride5  stride6  \n",
       "0           0.0055        3        3       4        1        1        1  \n",
       "1           0.0055        3        1       1        1        1        1  \n",
       "2           0.0055        3        3       3        1        1        1  \n",
       "3           0.0055        3        1       1        1        1        1  \n",
       "4           0.0055        3        3       1        1        1        1  \n",
       "5           0.0055        3        2       3        1        1        1  \n",
       "6           0.0055        3        3       4        1        1        1  \n",
       "7           0.0055        3        4       3        1        1        1  \n",
       "8           0.0055        3        1       2        1        1        1  \n",
       "9           0.0055        3        4       2        1        1        1  \n",
       "10          0.0055        3        4       3        1        1        1  \n",
       "11          0.0055        3        4       2        1        1        1  \n",
       "12          0.0055        3        1       1        1        1        1  \n",
       "13          0.0055        3        1       3        1        1        1  \n",
       "14          0.0055        3        3       3        1        1        1  \n",
       "15          0.0055        3        4       3        1        1        1  \n",
       "16          0.0055        3        1       2        1        1        1  \n",
       "17          0.0055        3        4       2        1        1        1  \n",
       "18          0.0055        3        4       4        1        1        1  \n",
       "19          0.0055        3        1       4        1        1        1  \n",
       "20          0.0055        3        2       2        1        1        1  \n",
       "21          0.0055        3        4       3        1        1        1  \n",
       "22          0.0055        3        4       4        1        1        1  \n",
       "23          0.0055        3        1       3        1        1        1  \n",
       "24          0.0055        3        3       3        1        1        1  \n",
       "25          0.0055        3        3       4        1        1        1  \n",
       "26          0.0055        3        2       2        1        1        1  \n",
       "27          0.0055        3        1       2        1        1        1  \n",
       "28          0.0055        3        3       3        1        1        1  \n",
       "29          0.0055        3        2       1        1        1        1  \n",
       "30          0.0055        3        4       4        1        1        1  \n",
       "31          0.0055        3        2       1        1        1        1  \n",
       "32          0.0055        3        3       2        1        1        1  \n",
       "33          0.0055        3        4       4        1        1        1  \n",
       "34          0.0055        3        3       2        1        1        1  \n",
       "\n",
       "[35 rows x 48 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
